[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CAPESData",
    "section": "",
    "text": "Este conjunto de documentos contém instruções, exemplos, scripts, etc. para acessar dados da CAPES, em particular dados de interesse de coordenadores de programas de pós-graduação e gestores.\nEstá em desenvolvimento (em 2024), mas resolvi publicar alguns exemplos que já podem ser úteis para alguns colegas.\nAlgumas observações sobre estes documentos:\n\nDou mais ênfase a reprodutibilidade e simplicidade do código do que a eficiência.\nOnde possível detalhei como obter os dados, mas em alguns casos as fontes de dados só podem ser acessadas por coordenadores de programas (ex. via plataforma Sucupira).\nNão posso garantir que os exemplos e códigos vão funcionar sempre, mas como este é um notebook o código que aparece nele foi executado para mostrar os resultados – ao menos uma vez funcionou!\nVeja na barra à esquerda o que já está pronto.\n\nEste material foi preparando usando Quarto, com código em Python, usando Visual Studio Code como ambiente de desenvolviumento integrado.\n\n\nSe seu interesse são nas análises já prontas (por exemplo, para usar os gráficos já preparados feitos com os dados abertos da Plataforma Sucupira) pule as páginas cujos títulos iniciam com Baixando ou Pré-Processamento. Estas páginas mostram como baixar os dados das fontes originais e preparar estes dados para os relatórios e gráficos, e são úteis para reproduzir e ampliar os escopos das análises.\nSe você quer reproduzir alguns dos exemplos usando informações de seu interesse (por exemplo, de seu programa, IES/ICT, área, região geográfica, etc.) copie o código em Python relevante – está razoavelmente documentado. Verifique antes as dependências de dados preprocessados – também estão documentadas, provavelmente nas páginas cujos títulos iniciam com Baixando ou Pré-Processamento.\nEm caso de dúvida entre em contato (veja link no rodapé das páginas). Não posso garantir respostas rápidas mas tentarei responder todas as mensagens.",
    "crumbs": [
      "Sobre"
    ]
  },
  {
    "objectID": "index.html#sobre",
    "href": "index.html#sobre",
    "title": "CAPESData",
    "section": "",
    "text": "Este conjunto de documentos contém instruções, exemplos, scripts, etc. para acessar dados da CAPES, em particular dados de interesse de coordenadores de programas de pós-graduação e gestores.\nEstá em desenvolvimento (em 2024), mas resolvi publicar alguns exemplos que já podem ser úteis para alguns colegas.\nAlgumas observações sobre estes documentos:\n\nDou mais ênfase a reprodutibilidade e simplicidade do código do que a eficiência.\nOnde possível detalhei como obter os dados, mas em alguns casos as fontes de dados só podem ser acessadas por coordenadores de programas (ex. via plataforma Sucupira).\nNão posso garantir que os exemplos e códigos vão funcionar sempre, mas como este é um notebook o código que aparece nele foi executado para mostrar os resultados – ao menos uma vez funcionou!\nVeja na barra à esquerda o que já está pronto.\n\nEste material foi preparando usando Quarto, com código em Python, usando Visual Studio Code como ambiente de desenvolviumento integrado.\n\n\nSe seu interesse são nas análises já prontas (por exemplo, para usar os gráficos já preparados feitos com os dados abertos da Plataforma Sucupira) pule as páginas cujos títulos iniciam com Baixando ou Pré-Processamento. Estas páginas mostram como baixar os dados das fontes originais e preparar estes dados para os relatórios e gráficos, e são úteis para reproduzir e ampliar os escopos das análises.\nSe você quer reproduzir alguns dos exemplos usando informações de seu interesse (por exemplo, de seu programa, IES/ICT, área, região geográfica, etc.) copie o código em Python relevante – está razoavelmente documentado. Verifique antes as dependências de dados preprocessados – também estão documentadas, provavelmente nas páginas cujos títulos iniciam com Baixando ou Pré-Processamento.\nEm caso de dúvida entre em contato (veja link no rodapé das páginas). Não posso garantir respostas rápidas mas tentarei responder todas as mensagens.",
    "crumbs": [
      "Sobre"
    ]
  },
  {
    "objectID": "index.html#glossário",
    "href": "index.html#glossário",
    "title": "CAPESData",
    "section": "Glossário",
    "text": "Glossário\n\nCAPES\n\nA Coordenação de Aperfeiçoamento de Pessoal de Nível Superior é uma Fundação do Ministério da Educação (MEC) que tem como missão a expansão e consolidação da pós-graduação stricto sensu (mestrado e doutorado) e formação de professores da educação básica no Brasil.\n\nSucupira (Plataforma Sucupira)\n\nA Plataforma Sucupira é um conjunto de ferramentas para coleta, análise e disseminação de dados dos programas de pós-graduação do Brasil, apoiando o Sistema Nacional de Pós-Graduação (SNPG). Algumas de suas funções são o módulo de envio de dados dos programas de pós-graduação (Coleta) e o catálogo de periódicos avaliados (Qualis). A nova versão da plataforma permite consultas detalhadas aos dados submetidos.",
    "crumbs": [
      "Sobre"
    ]
  },
  {
    "objectID": "index.html#alternativas",
    "href": "index.html#alternativas",
    "title": "CAPESData",
    "section": "Alternativas",
    "text": "Alternativas\nSe seu objetivo é analisar dados da CAPES, em especial de programas de pós-graduação, existem várias alternativas que não envolvem programação e/ou cópias locais das bases de dados. Algumas são:\n\nA nova versão da Plataforma Sucupira que contém relatórios sobre cursos avaliados e reconhecidos e o Observatório da pós-graduação.\nO Sistema Tarrafa, desenvolvido pela Unimontes – Universidade Estadual de Montes Claros, que usa dados da CAPES e CNPq para criar relatórios complexos e comparativos entre programas de pós-graduação.",
    "crumbs": [
      "Sobre"
    ]
  },
  {
    "objectID": "sucupira-producao-eda.html",
    "href": "sucupira-producao-eda.html",
    "title": "Análise de Básica de Dados da Plataforma Sucupira",
    "section": "",
    "text": "Na seção Baixando os dados obtivemos vários dados da Plataforma Sucupira, e na seção Pré-Processamento dos Dados reorganizamos os dados baixados em dataframes.\nNeste documento veremos como criar alguns gráficos sobre a produção intelectual do nosso programa. Os códigos neste documento assumem que os dataframes foram pré-processados e armazenados como mostrado na seção Pré-Processamento dos Dados.",
    "crumbs": [
      "Dados do Coleta",
      "Análise Básica"
    ]
  },
  {
    "objectID": "sucupira-producao-eda.html#sobre",
    "href": "sucupira-producao-eda.html#sobre",
    "title": "Análise de Básica de Dados da Plataforma Sucupira",
    "section": "",
    "text": "Na seção Baixando os dados obtivemos vários dados da Plataforma Sucupira, e na seção Pré-Processamento dos Dados reorganizamos os dados baixados em dataframes.\nNeste documento veremos como criar alguns gráficos sobre a produção intelectual do nosso programa. Os códigos neste documento assumem que os dataframes foram pré-processados e armazenados como mostrado na seção Pré-Processamento dos Dados.",
    "crumbs": [
      "Dados do Coleta",
      "Análise Básica"
    ]
  },
  {
    "objectID": "sucupira-producao-eda.html#análise-exploratória-de-dados",
    "href": "sucupira-producao-eda.html#análise-exploratória-de-dados",
    "title": "Análise de Básica de Dados da Plataforma Sucupira",
    "section": "Análise Exploratória de Dados",
    "text": "Análise Exploratória de Dados\nAntes de mostrar os gráficos e códigos que os criaram vamos importar as bibliotecas necessárias. Usaremos a biblioteca Plotly para os gráficos:\n\nimport pandas as pd\nimport plotly.graph_objs as go\nimport plotly.express as px\n\n\nQual é o perfil de nossa produção tecnológica?\nPodemos ver a quantidade e proporção dos diferentes tipos de produção tecnológica com um gráfico do tipo sunburst. Primeiro lemos o dataframe com toda a produção unificada:\n\ndir = \"Resources/Data/ColetaSucupira/\"\ndf = pd.read_csv(dir+\"CategoriaDeAutoresPorProdução-Unificada.csv\")\n\nPara criar um gráfico do tipo sunburst é preciso agrupar os dados do dataframe pelos níveis hierárquicos desejados, calculando a quantidade de itens que pertence a cada combinação dos níveis. O código a seguir faz isto:\n\ndfAgrupado = df.groupby(['Tipo da Produção', 'Subtipo da Produção']).\\\n                         size().reset_index(name='Total')\n# Criamos a figura.\nfig = px.sunburst(dfAgrupado, path=['Tipo da Produção', 'Subtipo da Produção'], \n                  values='Total')\nfig.update_traces(hovertemplate='&lt;b&gt;Tipo:&lt;/b&gt; %{label}&lt;br&gt;'+\n                                '&lt;b&gt;Subtipo:&lt;/b&gt; %{parent}&lt;br&gt;'+\n                                '&lt;b&gt;Total:&lt;/b&gt; %{value}')\nfig.show()\n\n                                                \n\n\n\n\nQual é a evolução da nossa produção tecnológica?\nPodemos ver o total por ano das produções tecnológicas de nosso programa com um gráfico de barras. Primeiro é preciso agrupar as produções por ano:\n\ndfProdPorAno = df.groupby('Ano da Produção').size()\n\nCom as produções agrupadas podemos criar um gráfico de barras com o código abaixo:\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n              x=dfProdPorAno.index,y=dfProdPorAno.values,\n              text=dfProdPorAno.values,\n              marker_color='#1269B1'))\nfig.update_layout(title='Produções Intelectuais por Ano',\n                  xaxis=dict(title='Ano', tickmode='linear', tick0=0, dtick=1),\n                  yaxis=dict(title='Produções'))    \nfig.show()    \n\n                                                \n\n\nPodemos detalhar o gráfico usando cores diferentes para cada tipo e subtipo da produção. Como temos 14 ou mais combinações de tipos e subtipos será melhor fazer dois gráficos separados, um para Tipo da Produção = BIBLIOGRÁFICA e outro para Tipo da Produção = TÉCNICA.\nVamos começar com as produções bibliográficas, criando um subconjunto do dataframe completo e agrupando por ano e subtipo:\n\ndfProdBibliográfica = df[df['Tipo da Produção'] == 'BIBLIOGRÁFICA']\ndfProdPorAnoECat = dfProdBibliográfica.groupby(['Ano da Produção', \n                                                'Subtipo da Produção']).\\\n                                                 size().reset_index(name='Produções')\n\nA criação do gráfico de barras empilhadas é feita com este código:\n\nfig = px.bar(dfProdPorAnoECat, \n             x='Ano da Produção',y='Produções', \n             color='Subtipo da Produção', \n             barmode='stack')\nfig.update_layout(title='Produções Bibliográficas por Ano',\n                  xaxis=dict(title='Ano', tickmode='linear', tick0=0, dtick=1),\n                  yaxis=dict(title='Produções'))    \nfig.show()\n\n                                                \n\n\nAgora faremos o mesmo para produções técnicas:\n\ndfProdTécnica = df[df['Tipo da Produção'] == 'TÉCNICA']\ndfProdPorAnoECat = dfProdTécnica.groupby(['Ano da Produção', \n                                          'Subtipo da Produção']).\\\n                                          size().reset_index(name='Produções')\n\nUsamos basicamente o mesmo código para criar o gráfico de barras empilhadas:\n\nfig = px.bar(dfProdPorAnoECat, \n             x='Ano da Produção',y='Produções', \n             color='Subtipo da Produção', \n             barmode='stack')\nfig.update_layout(title='Produções Técnicas por Ano',\n                  xaxis=dict(title='Ano', tickmode='linear', tick0=0, dtick=1),\n                  yaxis=dict(title='Produções'))    \nfig.show()\n\n                                                \n\n\n\n\nQual é a evolução da nossa produção tecnológica (com coautoria discente)?\nVamos ver quanto da nossa produção tecnológica tem coautoria discente por ano. Para isto preciso separar o dataframe em dois complementares, e agrupar estes dois pelo ano da produção:\n\ndfProdComDisc = df[df['Discente'] &gt; 0]\ndfProdComDisc = dfProdComDisc.groupby('Ano da Produção').size()\ndfProdSemDisc = df[df['Discente'] == 0]\ndfProdSemDisc = dfProdSemDisc.groupby('Ano da Produção').size()\n\nVamos usar dois traços no gráfico:\n\ntraçoComDiscentes = go.Bar(x=dfProdComDisc.index,y=dfProdComDisc.values,\n                           name='Com Discentes',marker_color='#0dbf7b')\ntraçoSemDiscentes = go.Bar(x=dfProdSemDisc.index,y=dfProdSemDisc.values,\n                           name='Sem Discentes',marker_color='#220dbf')\n\nCriamos e ajustamos a figura:\n\nfig = go.Figure(data=[traçoComDiscentes, traçoSemDiscentes])\nfig.update_layout(\n    title='Produções Intelectuais por Ano (com participação de discentes)',\n    xaxis=dict(title='Ano', tickmode='linear', tick0=0, dtick=1),\n    yaxis=dict(title='Produções'),\n    barmode='stack')\nfig.show()\n\n                                                \n\n\nMas queremos visualizar também as produções bibliográficas com coautoria por ano. Vamos refazer o dataframe com este filtro adicional:\n\ndfProdComDisc = dfProdBibliográfica[dfProdBibliográfica['Discente'] &gt; 0]\ndfProdComDisc = dfProdComDisc.groupby('Ano da Produção').size()\ndfProdSemDisc = dfProdBibliográfica[dfProdBibliográfica['Discente'] == 0]\ndfProdSemDisc = dfProdSemDisc.groupby('Ano da Produção').size()\n\nRecriamos os traços:\n\ntraçoComDiscentes = go.Bar(x=dfProdComDisc.index,y=dfProdComDisc.values,\n                           name='Com Discentes',marker_color='#0dbf7b')\ntraçoSemDiscentes = go.Bar(x=dfProdSemDisc.index,y=dfProdSemDisc.values,\n                           name='Sem Discentes',marker_color='#220dbf')\n\nE o gráfico, com basicamente os mesmos comandos de antes.\n\nfig = go.Figure(data=[traçoComDiscentes, traçoSemDiscentes])\nfig.update_layout(\n    title='Produções Bibliográficas por Ano (com participação de discentes)',\n    xaxis=dict(title='Ano', tickmode='linear', tick0=0, dtick=1),\n    yaxis=dict(title='Produções'),\n    barmode='stack')\nfig.show()\n\n                                                \n\n\n\n\nQual é a evolução da nossa produção tecnológica (com único autor)?\nUm dos indicadores da interdisciplinaridade é a quantidade de publicações em coautorias. Para verificar o histórico destas publicações vamos criar um novo campo para o dataframe original que contém a quantidade de autores independente da categoria:\n\ndf['NumAutores'] = df[['Docente', 'Egresso', 'Participante Externo', \\\n                       'Pós-Doc', 'Sem Categoria', 'Discente']].sum(axis=1)\n\nVamos considerar somente produções do tipo BIBLIOGRÁFICA:\n\ndfProdBibliográfica = df[df['Tipo da Produção'] == 'BIBLIOGRÁFICA']\n\nCom isto podemos criar os dataframes filtrados:\n\ndfProdCom1 = dfProdBibliográfica[dfProdBibliográfica['NumAutores'] == 1]\ndfProdCom1 = dfProdCom1.groupby('Ano da Produção').size()\ndfProdComN = dfProdBibliográfica[dfProdBibliográfica['NumAutores'] &gt; 1]\ndfProdComN = dfProdComN.groupby('Ano da Produção').size()\n\nE agora os traços:\n\ntraçoCom1 = go.Bar(x=dfProdCom1.index,y=dfProdCom1.values,\n                   name='Um Autor',marker_color='#0dbf7b')\ntraçoComN = go.Bar(x=dfProdComN.index,y=dfProdComN.values,\n                   name='Vários Autores',marker_color='#220dbf')\n\n\nfig = go.Figure(data=[traçoCom1, traçoComN])\nfig.update_layout(\n    title='Produções Bibliográficas por Ano (com coautorias)',\n    xaxis=dict(title='Ano', tickmode='linear', tick0=0, dtick=1),\n    yaxis=dict(title='Produções'),\n    barmode='stack')\nfig.show()",
    "crumbs": [
      "Dados do Coleta",
      "Análise Básica"
    ]
  },
  {
    "objectID": "dadosabertos-preprocessamento-cursos.html",
    "href": "dadosabertos-preprocessamento-cursos.html",
    "title": "Pré-Processamento dos Dados - Cursos",
    "section": "",
    "text": "Nesta seção vamos ler, verificar e unificar os dados sobre cursos, baixados do Portal de Dados Abertos, transformando as planilhas em bases de dados que facilitarão as análises.\n\n\nVimos na tabela de arquivos baixados que todos os arquivos (cobrindo os anos entre 2013 e 2023) tem o nesmo número de colunas (28). Primeiramente vamos ver se todas as planilhas contém as mesmas colunas.\nImportamos as bibliotecas necessárias:\n\nimport pandas as pd\nimport glob\nimport re\nimport warnings\n\nCriamos uma lista com todas as planilhas com dados dos cursos:\n\narquivos = glob.glob('Resources/Data/DadosAbertos/br-capes-colsucup-curso*.xlsx')\n\nLemos todas as planilhas, armazenando as suas colunas em uma lista de colunas:\n\ncolunas = []\nfor arquivo in arquivos:\n    # Evitamos mensagens sobre importação de planilhas.\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, \n                                module=re.escape('openpyxl.styles.stylesheet'))\n        df = pd.read_excel(arquivo)\n        colunas.append(df.columns.tolist())\n\nVerificamos se todas as listas de colunas são iguais à primeira:\n\n# Usamos a primeira coluna como padrão.\ncolunasPadrão = colunas[0]\n# Criamos uma lista de diferenças.\ndiferenças = []\n# Para cada lista de colunas...\nfor idx, columns in enumerate(colunas):\n    # Se for diferente do padrão...\n    if columns != colunasPadrão:\n        # Adicionamos à lista de diferenças.\n        diferenças.append((arquivos[idx], columns))\n\n# Mostramos o resultado: se tivermos alguma diferença\nif diferenças:\n    print(\"Os seguintes arquivos tem colunas diferentes:\")\n    for arq, cols in diferenças:\n        print(f\"{arq}: {cols}\")\nelse:\n    print(\"Todos os arquivos tem as mesmas colunas.\")\n\nTodos os arquivos tem as mesmas colunas.\n\n\nPara este caso específico verificamos que todos os arquivos tem as mesmas colunas Isto não acontecerá em outros conjuntos de dados, portanto o trecho de código acima será útil para identificar diferenças entre campos de planilhas de um mesmo conjunto.\n\n\n\nCada uma das planilhas desta coleção de dados corresponde aos dados coletados em determinado ano – podemos ver na tabela de arquivos baixados que o número de linhas por ano aumenta gradativamente, contendo informações sobre novos cursos (e eventualmente retirando informações sobre cursos desativados). É interessante então manter a informação por ano e por curso ao unificar os dados.\nVamos primeiro ler todos os arquivos e colocá-los em uma lista de dataframes:\n\ndfs = []\n# Para cada arquivo na lista de arquivos de planilhas:\nfor arquivo in arquivos:\n    # Evitamos mensagens sobre importação de planilhas.\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, \n                                module=re.escape('openpyxl.styles.stylesheet'))\n        df = pd.read_excel(arquivo)\n        dfs.append(df)\n\nPodemos então concatenar todos os dataframes em um só:\n\ndadosCombinados = pd.concat(dfs, ignore_index=True)\n\nNem todos os campos do dataframe unificado tem utilidade direta para as análises e gráficos sendo considerados. Por simplicidade, podemos eliminar os que não serão. Na mesma página onde temos acesso aos links das planilhas podemos baixar o documento Metadados de Cursos da Pós-Graduação, que mostra todos os campos das planilhas. Destes manteremos os mostrados na lista a seguir:\n\nAN_BASE: Ano de referência da coleta dos dados\nNM_GRANDE_AREA_CONHECIMENTO: Grande Área de Conhecimento à qual o programa de pós-graduação está vinculado\nNM_AREA_CONHECIMENTO: Área de Conhecimento à qual o programa de pós-graduação está vinculado\nNM_SUBAREA_CONHECIMENTO: Subárea de Conhecimento à qual o Programa de pós-graduação está vinculado\nNM_ESPECIALIDADE: Especialidade do conhecimento à qual o programa de pós-graduação está vinculado\nCD_AREA_AVALIACAO: Código identificador da área de avaliação do programa de pós-graduação\nNM_AREA_AVALIACAO: Área de avaliação do programa de pós-graduação\nCD_ENTIDADE_CAPES: Código da Instituição de Ensino Superior na CAPES\nSG_ENTIDADE_ENSINO: Sigla da Instituição de Ensino Superior do programa de pós-graduação\nNM_ENTIDADE_ENSINO: Instituição de Ensino Superior do programa de pós-graduação\nCS_STATUS_JURIDICO: Classificação da Natureza Jurídica da Instituição do programa de pós-graduação\nDS_DEPENDENCIA_ADMINISTRATIVA: Descrição da Dependência Administrativa da Instituição de Ensino do programa de pós-graduação\nDS_ORGANIZACAO_ACADEMICA: Organização acadêmica da Instituição de Ensino Superior\nNM_REGIAO: Nome da Região\nSG_UF_PROGRAMA: Sigla da Unidade da Federação do programa discrete character\nNM_MUNICIPIO_PROGRAMA_IES: Município sede do programa de pós-graduação\nCD_PROGRAMA_IES: Código do programa de pós-graduação na CAPES\nNM_PROGRAMA_IES: Nome do programa de pós-graduação discrete character\nCD_CURSO_PPG: Código do Curso de pós-Graduação na CAPES\nNM_CURSO: Nome do curso de pós-graduação\nNM_GRAU_CURSO: Grau acadêmico do curso de pós-graduação\nCD_CONCEITO_CURSO: Código do conceito do curso\nAN_INICIO_PREVISTO: Ano de ínicio previsto para o curso\nDS_SITUACAO_CURSO: Situação de atividade do curso d\nDT_SITUACAO_CURSO: Data da situação do curso\n\nPodemos filtrar o dataframe mantendo somente estes campos, mas o código para filtrar os campos não necessários é mais simples. Usamos o documento de metadados como referência para criar uma lista de campos a serem filtrados:\n\nfiltrar = ['CD_ENTIDADE_EMEC','ID_ADD_FOTO_PROGRAMA_IES',\n           'ID_ADD_FOTO_PROGRAMA']\ndadosFiltrados = dadosCombinados.drop(columns=filtrar)\n\nFinalmente podemos armazenar o dataframe com os dados das planilhas unificadas e sem as colunas desnecessárias em um arquivo local:\n\ndadosFiltrados.to_csv('Resources/Data/DadosAbertos/Cursos.csv', index=False)\n\nQual é o tamanho da nossa base de dados em linhas e colunas?\n\nlinhas, colunas = dadosFiltrados.shape\nprint(f\"A base tem {linhas} linhas (registros) e {colunas} colunas (campos).\")\n\nA base tem 65202 linhas (registros) e 25 colunas (campos)."
  },
  {
    "objectID": "dadosabertos-preprocessamento-cursos.html#sobre",
    "href": "dadosabertos-preprocessamento-cursos.html#sobre",
    "title": "Pré-Processamento dos Dados - Cursos",
    "section": "",
    "text": "Nesta seção vamos ler, verificar e unificar os dados sobre cursos, baixados do Portal de Dados Abertos, transformando as planilhas em bases de dados que facilitarão as análises.\n\n\nVimos na tabela de arquivos baixados que todos os arquivos (cobrindo os anos entre 2013 e 2023) tem o nesmo número de colunas (28). Primeiramente vamos ver se todas as planilhas contém as mesmas colunas.\nImportamos as bibliotecas necessárias:\n\nimport pandas as pd\nimport glob\nimport re\nimport warnings\n\nCriamos uma lista com todas as planilhas com dados dos cursos:\n\narquivos = glob.glob('Resources/Data/DadosAbertos/br-capes-colsucup-curso*.xlsx')\n\nLemos todas as planilhas, armazenando as suas colunas em uma lista de colunas:\n\ncolunas = []\nfor arquivo in arquivos:\n    # Evitamos mensagens sobre importação de planilhas.\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, \n                                module=re.escape('openpyxl.styles.stylesheet'))\n        df = pd.read_excel(arquivo)\n        colunas.append(df.columns.tolist())\n\nVerificamos se todas as listas de colunas são iguais à primeira:\n\n# Usamos a primeira coluna como padrão.\ncolunasPadrão = colunas[0]\n# Criamos uma lista de diferenças.\ndiferenças = []\n# Para cada lista de colunas...\nfor idx, columns in enumerate(colunas):\n    # Se for diferente do padrão...\n    if columns != colunasPadrão:\n        # Adicionamos à lista de diferenças.\n        diferenças.append((arquivos[idx], columns))\n\n# Mostramos o resultado: se tivermos alguma diferença\nif diferenças:\n    print(\"Os seguintes arquivos tem colunas diferentes:\")\n    for arq, cols in diferenças:\n        print(f\"{arq}: {cols}\")\nelse:\n    print(\"Todos os arquivos tem as mesmas colunas.\")\n\nTodos os arquivos tem as mesmas colunas.\n\n\nPara este caso específico verificamos que todos os arquivos tem as mesmas colunas Isto não acontecerá em outros conjuntos de dados, portanto o trecho de código acima será útil para identificar diferenças entre campos de planilhas de um mesmo conjunto.\n\n\n\nCada uma das planilhas desta coleção de dados corresponde aos dados coletados em determinado ano – podemos ver na tabela de arquivos baixados que o número de linhas por ano aumenta gradativamente, contendo informações sobre novos cursos (e eventualmente retirando informações sobre cursos desativados). É interessante então manter a informação por ano e por curso ao unificar os dados.\nVamos primeiro ler todos os arquivos e colocá-los em uma lista de dataframes:\n\ndfs = []\n# Para cada arquivo na lista de arquivos de planilhas:\nfor arquivo in arquivos:\n    # Evitamos mensagens sobre importação de planilhas.\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, \n                                module=re.escape('openpyxl.styles.stylesheet'))\n        df = pd.read_excel(arquivo)\n        dfs.append(df)\n\nPodemos então concatenar todos os dataframes em um só:\n\ndadosCombinados = pd.concat(dfs, ignore_index=True)\n\nNem todos os campos do dataframe unificado tem utilidade direta para as análises e gráficos sendo considerados. Por simplicidade, podemos eliminar os que não serão. Na mesma página onde temos acesso aos links das planilhas podemos baixar o documento Metadados de Cursos da Pós-Graduação, que mostra todos os campos das planilhas. Destes manteremos os mostrados na lista a seguir:\n\nAN_BASE: Ano de referência da coleta dos dados\nNM_GRANDE_AREA_CONHECIMENTO: Grande Área de Conhecimento à qual o programa de pós-graduação está vinculado\nNM_AREA_CONHECIMENTO: Área de Conhecimento à qual o programa de pós-graduação está vinculado\nNM_SUBAREA_CONHECIMENTO: Subárea de Conhecimento à qual o Programa de pós-graduação está vinculado\nNM_ESPECIALIDADE: Especialidade do conhecimento à qual o programa de pós-graduação está vinculado\nCD_AREA_AVALIACAO: Código identificador da área de avaliação do programa de pós-graduação\nNM_AREA_AVALIACAO: Área de avaliação do programa de pós-graduação\nCD_ENTIDADE_CAPES: Código da Instituição de Ensino Superior na CAPES\nSG_ENTIDADE_ENSINO: Sigla da Instituição de Ensino Superior do programa de pós-graduação\nNM_ENTIDADE_ENSINO: Instituição de Ensino Superior do programa de pós-graduação\nCS_STATUS_JURIDICO: Classificação da Natureza Jurídica da Instituição do programa de pós-graduação\nDS_DEPENDENCIA_ADMINISTRATIVA: Descrição da Dependência Administrativa da Instituição de Ensino do programa de pós-graduação\nDS_ORGANIZACAO_ACADEMICA: Organização acadêmica da Instituição de Ensino Superior\nNM_REGIAO: Nome da Região\nSG_UF_PROGRAMA: Sigla da Unidade da Federação do programa discrete character\nNM_MUNICIPIO_PROGRAMA_IES: Município sede do programa de pós-graduação\nCD_PROGRAMA_IES: Código do programa de pós-graduação na CAPES\nNM_PROGRAMA_IES: Nome do programa de pós-graduação discrete character\nCD_CURSO_PPG: Código do Curso de pós-Graduação na CAPES\nNM_CURSO: Nome do curso de pós-graduação\nNM_GRAU_CURSO: Grau acadêmico do curso de pós-graduação\nCD_CONCEITO_CURSO: Código do conceito do curso\nAN_INICIO_PREVISTO: Ano de ínicio previsto para o curso\nDS_SITUACAO_CURSO: Situação de atividade do curso d\nDT_SITUACAO_CURSO: Data da situação do curso\n\nPodemos filtrar o dataframe mantendo somente estes campos, mas o código para filtrar os campos não necessários é mais simples. Usamos o documento de metadados como referência para criar uma lista de campos a serem filtrados:\n\nfiltrar = ['CD_ENTIDADE_EMEC','ID_ADD_FOTO_PROGRAMA_IES',\n           'ID_ADD_FOTO_PROGRAMA']\ndadosFiltrados = dadosCombinados.drop(columns=filtrar)\n\nFinalmente podemos armazenar o dataframe com os dados das planilhas unificadas e sem as colunas desnecessárias em um arquivo local:\n\ndadosFiltrados.to_csv('Resources/Data/DadosAbertos/Cursos.csv', index=False)\n\nQual é o tamanho da nossa base de dados em linhas e colunas?\n\nlinhas, colunas = dadosFiltrados.shape\nprint(f\"A base tem {linhas} linhas (registros) e {colunas} colunas (campos).\")\n\nA base tem 65202 linhas (registros) e 25 colunas (campos)."
  },
  {
    "objectID": "dadosabertos-analise-cursos.html",
    "href": "dadosabertos-analise-cursos.html",
    "title": "Análises e Gráficos sobre Cursos",
    "section": "",
    "text": "Os dados sobre cursos foram baixados do Portal de Dados Abertos e preparados para análise.\nNeste documento veremos como criar alguns gráficos sobre os cursos e programas de pós-graduação usando estes dados."
  },
  {
    "objectID": "dadosabertos-analise-cursos.html#sobre",
    "href": "dadosabertos-analise-cursos.html#sobre",
    "title": "Análises e Gráficos sobre Cursos",
    "section": "",
    "text": "Os dados sobre cursos foram baixados do Portal de Dados Abertos e preparados para análise.\nNeste documento veremos como criar alguns gráficos sobre os cursos e programas de pós-graduação usando estes dados."
  },
  {
    "objectID": "dadosabertos-analise-cursos.html#análise-exploratória-de-dados",
    "href": "dadosabertos-analise-cursos.html#análise-exploratória-de-dados",
    "title": "Análises e Gráficos sobre Cursos",
    "section": "Análise Exploratória de Dados",
    "text": "Análise Exploratória de Dados\nVamos iniciar com algumas perguntas básicas sobre os dados que podem ser respondidas em poucas linhas de código. Começamos importando as bibliotecas básicas:\n\nimport pandas as pd\nimport plotly.express as px\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nVamos também ler a base de dados unificada.\n\nbase = pd.read_csv(\"Resources/Data/DadosAbertos/Cursos.csv\")\n\nPara algumas análise vamos querer somente os cursos que estão em funcionamento em 2022 (ano mais recente com dados disponíveis na CAPES). Vamos criar uma versão filtrada da base:\n\nbase2022 = base[(base['AN_BASE'] == 2022) & \n                (base['DS_SITUACAO_CURSO'] == \"EM FUNCIONAMENTO\")]\n\n\nQuantos programas de pós-graduação temos na base?\nPara calcular quantos programas temos (lembrando que a base cobre vários anos e os programas podem aparecer mais de uma vez) contamos os valores únicos dos campos CD_PROGRAMA_IES e CD_CURSO_PPG:\n\n# Contamos os valores únicos para programas e cursos, para a base completa.\nprogramas = base['CD_PROGRAMA_IES'].nunique()\ncursos = base['CD_CURSO_PPG'].nunique()\n# Mostramos o resultado:\nprint(f\"Temos {programas} programas e {cursos} cursos na base completa.\")\n# Contamos os valores únicos para programas e cursos, para a base de programas em\n# funcionamento em 2022.\nprogramas = base2022['CD_PROGRAMA_IES'].nunique()\ncursos = base2022['CD_CURSO_PPG'].nunique()\n# Mostramos o resultado:\nprint(f\"Temos {programas} programas e {cursos} cursos na base de programas\\n\"+\n       \"\\tem funcionamento em 2022.\")\n\nTemos 4911 programas e 7409 cursos na base completa.\nTemos 4577 programas e 6985 cursos na base de programas\n    em funcionamento em 2022.\n\n\n\nQuantos por estado?\nPara fazer a contagem de programas por estado primeiro agrupamos os valores por estado, selecionamos os programas e contamos quantos programas únicos temos. O resultado é ordenado pela contagem, do maior valor para o menor. Preservamos a região dos estados para uso posterior.\n\nporEstado = base2022.groupby(['SG_UF_PROGRAMA', 'NM_REGIAO'])\\\n                             ['CD_PROGRAMA_IES'].nunique().reset_index()\nporEstado = porEstado.sort_values(by='CD_PROGRAMA_IES',ascending=False)\n\nMostramos o resultado como uma tabela:\n\nMarkdown(tabulate(\n  porEstado, \n  headers=[\"Estado\",\"Região\",\"Programas\"],\n  showindex=False,\n))\n\n\n\n\nEstado\nRegião\nProgramas\n\n\n\n\nSP\nSUDESTE\n912\n\n\nRJ\nSUDESTE\n510\n\n\nMG\nSUDESTE\n472\n\n\nRS\nSUL\n414\n\n\nPR\nSUL\n370\n\n\nBA\nNORDESTE\n207\n\n\nSC\nSUL\n187\n\n\nPE\nNORDESTE\n166\n\n\nCE\nNORDESTE\n146\n\n\nPA\nNORTE\n141\n\n\nGO\nCENTRO-OESTE\n126\n\n\nDF\nCENTRO-OESTE\n123\n\n\nPB\nNORDESTE\n113\n\n\nRN\nNORDESTE\n113\n\n\nMS\nCENTRO-OESTE\n80\n\n\nES\nSUDESTE\n74\n\n\nMA\nNORDESTE\n66\n\n\nMT\nCENTRO-OESTE\n66\n\n\nAM\nNORTE\n63\n\n\nSE\nNORDESTE\n55\n\n\nAL\nNORDESTE\n45\n\n\nPI\nNORDESTE\n44\n\n\nTO\nNORTE\n28\n\n\nRO\nNORTE\n17\n\n\nAC\nNORTE\n15\n\n\nRR\nNORTE\n14\n\n\nAP\nNORTE\n10\n\n\n\n\n\n\n\nQuantos por área de avaliação?\nA CAPES considera 50 áreas de avaliação. Quantos programas temos em cada área?\n\nporÁrea = base2022.groupby('NM_AREA_AVALIACAO')['CD_PROGRAMA_IES'].nunique().reset_index()\nporÁrea = porÁrea.sort_values(by='CD_PROGRAMA_IES',ascending=False)\n\nMostramos o resultado como uma tabela:\n\nMarkdown(tabulate(\n  porÁrea, \n  headers=[\"Área de Avaliação\",\"Programas\"],\n  showindex=False,\n))\n\n\n\n\nÁrea de Avaliação\nProgramas\n\n\n\n\nINTERDISCIPLINAR\n375\n\n\nCIÊNCIAS AGRÁRIAS I\n216\n\n\nEDUCAÇÃO\n190\n\n\nADMINISTRAÇÃO PÚBLICA E DE EMPRESAS, CIÊNCIAS CONTÁBEIS E TURISMO\n188\n\n\nENSINO\n181\n\n\nLINGUÍSTICA E LITERATURA\n156\n\n\nBIODIVERSIDADE\n142\n\n\nCIÊNCIAS AMBIENTAIS\n138\n\n\nDIREITO\n132\n\n\nENGENHARIAS I\n127\n\n\nENGENHARIAS III\n126\n\n\nMEDICINA I\n111\n\n\nMEDICINA II\n108\n\n\nPSICOLOGIA\n101\n\n\nODONTOLOGIA\n98\n\n\nSAÚDE COLETIVA\n97\n\n\nENGENHARIAS II\n94\n\n\nENGENHARIAS IV\n91\n\n\nCOMUNICAÇÃO E INFORMAÇÃO\n88\n\n\nCIÊNCIA DA COMPUTAÇÃO\n88\n\n\nMEDICINA VETERINÁRIA\n85\n\n\nHISTÓRIA\n81\n\n\nEDUCAÇÃO FÍSICA\n80\n\n\nENFERMAGEM\n78\n\n\nCIÊNCIAS BIOLÓGICAS II\n77\n\n\nGEOGRAFIA\n77\n\n\nQUÍMICA\n76\n\n\nECONOMIA\n75\n\n\nARTES\n70\n\n\nFARMÁCIA\n69\n\n\nBIOTECNOLOGIA\n65\n\n\nARQUITETURA, URBANISMO E DESIGN\n64\n\n\nASTRONOMIA / FÍSICA\n63\n\n\nCIÊNCIAS BIOLÓGICAS I\n62\n\n\nZOOTECNIA / RECURSOS PESQUEIROS\n61\n\n\nMATEMÁTICA / PROBABILIDADE E ESTATÍSTICA\n60\n\n\nCIÊNCIA POLÍTICA E RELAÇÕES INTERNACIONAIS\n60\n\n\nCIÊNCIA DE ALIMENTOS\n59\n\n\nGEOCIÊNCIAS\n58\n\n\nFILOSOFIA\n54\n\n\nMEDICINA III\n52\n\n\nSOCIOLOGIA\n51\n\n\nPLANEJAMENTO URBANO E REGIONAL / DEMOGRAFIA\n47\n\n\nMATERIAIS\n42\n\n\nANTROPOLOGIA / ARQUEOLOGIA\n37\n\n\nCIÊNCIAS BIOLÓGICAS III\n36\n\n\nSERVIÇO SOCIAL\n36\n\n\nNUTRIÇÃO\n34\n\n\nCIÊNCIAS DA RELIGIÃO E TEOLOGIA\n21\n\n\n\n\n\n\n\n\n\n\n\nAviso\n\n\n\nA base de dados usa dois campos para representar a área de avaliação: um com o código (CD_AREA_AVALIACAO) e um com o nome (NM_AREA_AVALIACAO). É importante observar que o mesmo código pode ser representado por dois nomes diferentes, como é o caso da área código 29, que é associada aos nomes das áreas ARQUITETURA, URBANISMO E DESIGN e ARQUITETURA E URBANISMO.\n\n\n\n\nQuantos programas Interdisciplinares por estado?\nVamos filtrar somente os com código da área de avaliação igual a 45, e agrupar por estado:\n\nbase45 = base2022[(base2022['CD_AREA_AVALIACAO'] == 45)] \nporEstado45 = base45.groupby(['SG_UF_PROGRAMA', 'NM_REGIAO'])\\\n                             ['CD_PROGRAMA_IES'].nunique().reset_index()\nporEstado45 = porEstado45.sort_values(by='CD_PROGRAMA_IES',ascending=False)\n\nMostramos o resultado como uma tabela:\n\nMarkdown(tabulate(\n  porEstado45, \n  headers=[\"Estado\",\"Região\",\"Programas\"],\n  showindex=False,\n))\n\n\n\n\nEstado\nRegião\nProgramas\n\n\n\n\nSP\nSUDESTE\n68\n\n\nRJ\nSUDESTE\n46\n\n\nRS\nSUL\n36\n\n\nBA\nNORDESTE\n30\n\n\nMG\nSUDESTE\n30\n\n\nPR\nSUL\n29\n\n\nPA\nNORTE\n18\n\n\nSC\nSUL\n15\n\n\nCE\nNORDESTE\n13\n\n\nGO\nCENTRO-OESTE\n12\n\n\nDF\nCENTRO-OESTE\n12\n\n\nMS\nCENTRO-OESTE\n8\n\n\nPE\nNORDESTE\n8\n\n\nMT\nCENTRO-OESTE\n5\n\n\nSE\nNORDESTE\n5\n\n\nRN\nNORDESTE\n5\n\n\nMA\nNORDESTE\n5\n\n\nRR\nNORTE\n4\n\n\nTO\nNORTE\n4\n\n\nES\nSUDESTE\n4\n\n\nAM\nNORTE\n4\n\n\nPI\nNORDESTE\n3\n\n\nRO\nNORTE\n3\n\n\nPB\nNORDESTE\n3\n\n\nAL\nNORDESTE\n3\n\n\nAP\nNORTE\n1\n\n\nAC\nNORTE\n1\n\n\n\n\n\n\n\nQuantos por Natureza Jurídica?\nVamos ver quantos programas temos para cada uma das naturezas jurídicas reconhecidas pela CAPES:\n\nporNatJur = base2022.groupby('CS_STATUS_JURIDICO')['CD_PROGRAMA_IES'].nunique().reset_index()\nporNatJur = porNatJur.sort_values(by='CD_PROGRAMA_IES',ascending=False)\n\nMostramos o resultado como uma tabela:\n\nMarkdown(tabulate(\n  porNatJur, \n  headers=[\"Natureza Jurídica\",\"Programas\"],\n  showindex=False,\n))\n\n\n\n\nNatureza Jurídica\nProgramas\n\n\n\n\nFEDERAL\n2703\n\n\nESTADUAL\n1042\n\n\nPARTICULAR\n797\n\n\nMUNICIPAL\n35\n\n\n\n\n\n\n\n\nMapas\n\nimport json\n\n\nwith open(\"Resources/Maps/brazil-states.geojson\", 'r') as f:\n    brazilGeojson = json.load(f)"
  },
  {
    "objectID": "dadosabertos-analise-cursos.html#alguns-cruzamentos-de-dados-com-fontes-externas",
    "href": "dadosabertos-analise-cursos.html#alguns-cruzamentos-de-dados-com-fontes-externas",
    "title": "Análises e Gráficos sobre Cursos",
    "section": "Alguns cruzamentos de dados com fontes externas",
    "text": "Alguns cruzamentos de dados com fontes externas\nVamos usar um dataframe com indicadores sociais e econômicos por estado, obtido do IBGE e já pré-processado, para visualizar relações entre PIB, percentual da população abaixo da linha de pobreza, número de escolas de ensino médio no estado, população e número de programas de pós-graduação.\n\n\n\n\n\n\nAviso\n\n\n\nOutras variáveis socioeconômicas podem ser escolhidas, visite a seção Dados do IBGE para ver como.\n\n\nPrimeiro lemos as duas bases de dados complementares:\n\ndadosSE = pd.read_csv(\"Resources/Data/OutrosDados/DadosIBGE.csv\")\ndadosPOP = pd.read_csv(\"Resources/Data/OutrosDados/IBGEPopulação.csv\")\n\nAs bases devem ser unidas pela sigla do estado, que é um campo comum a todas elas mas representada por colunas diferentes (SG_UF_PROGRAMA no dataframe com número de programas por estado e Sigla nos dataframes com dados socioeconômicos e de população).\n\n# Renomeamos a coluna que representa a sigla da UF nos dados por estado:\nporEstado.rename(columns={'SG_UF_PROGRAMA': 'Sigla'}, inplace=True)\n# Unimos com o dataframe de dados socioambientais:\nunião = pd.merge(porEstado, dadosSE, on='Sigla')\n# Unimos com o dataframe de dados de população, usando um sufixo para marcar\n# colunas que podem estar repetidas:\nunião = pd.merge(união, dadosPOP, on='Sigla',suffixes=('', '_POP'))\n# Eliminamos as colunas que podem estar repetidas usando o sufixo:\nunião = união.drop(columns=[col for col in união.columns if col.endswith('_POP')])\n\nAgora temos um dataframe com a quantidade de programas de pós-graduação por estado, anotado com várias variáveis socioambientais sobre os estados, mais população estratificada e área. Podemos explorar alguns gráficos que mostram relações entre estas variáveis.\nUm gráfico do tipo bolha pode mostrar as relações entre várias variáveis numéricas. Usaremos a biblioteca Plotly para criar o gráfico, com bolhas representando os estados, tamanho das bolhas proporcionais ao número de programas e cores representando as regiões.\nVamos visualizar a área do estado e total da população com o número de programas de pós-graduação por estado:\n\n# Criamos o gráfico.\nfig = px.scatter(união, \n                 x='Área', \n                 y='Total', \n                 size='CD_PROGRAMA_IES', \n                 color='NM_REGIAO',\n                 hover_name='Sigla', \n                 size_max=100,\n                 title='Área x Total População x Programas de Pós-Graduação',\n                 labels={\n                   'Total': 'População Total',\n                 },\n                 custom_data=['NM_REGIAO','Área', 'Total', 'CD_PROGRAMA_IES'])\n# Modificamos o layout e customizamos a legenda flutuante.\nfig.update_layout(showlegend=False)\nfig.update_traces(\n    hovertemplate='&lt;b&gt;Estado: %{hovertext}&lt;/b&gt;&lt;br&gt;' +\n                  'Região: %{customdata[0]}&lt;br&gt;' +\n                  'Área: %{customdata[1]} km&#178;&lt;br&gt;' +\n                  'População: %{customdata[2]}&lt;br&gt;' +\n                  'Número de Programas: %{customdata[3]}&lt;br&gt;' +\n                  '&lt;extra&gt;&lt;/extra&gt;'\n)\n# Mostramos o gráfico:\nfig.show()\n\n                                                \n\n\nPara ver uma relação diferente vamos calcular o PIB per capita e plotar contra o percentual da população abaixo da linha de pobreza, usando como marcadores e número de programas de pós-graduação por estado:\n\n# Criamos uma nova coluna para o eixo X.\nunião['PIB_per_Capita'] = união['PIB'] / união['Total']\n# Criamos também uma versão formatada para uso no indicador flutuante.\nunião['fPIB_per_Capita'] = união['PIB_per_Capita'].apply(lambda x: f'{x:.2f}')\n# Criamos o gráfico.\nfig = px.scatter(união, \n                 x='PIB_per_Capita', \n                 y='PALB', \n                 size='CD_PROGRAMA_IES', \n                 color='NM_REGIAO',\n                 hover_name='Sigla', \n                 size_max=100,\n                 title='PIB per capita x PALB x Programas de Pós-Graduação',\n                 labels={\n                   'PIB_per_Capita': 'Produto Interno Bruto (PIB) per capita',\n                   'PALB': 'População Abaixo da Linha de Pobreza (%)',\n                 },\n                 custom_data=['NM_REGIAO', 'fPIB_per_Capita', 'Total', 'PALB', 'CD_PROGRAMA_IES'])\n# Modificamos o layout e customizamos a legenda flutuante.\nfig.update_layout(showlegend=False)\nfig.update_traces(\n    hovertemplate='&lt;b&gt;Estado: %{hovertext}&lt;/b&gt;&lt;br&gt;' +\n                  'Região: %{customdata[0]}&lt;br&gt;' +\n                  'PIB per capita: %{customdata[1]}&lt;br&gt;' +\n                  'População: %{customdata[2]}&lt;br&gt;' +\n                  '% Abaixo da Linha de Pobreza: %{customdata[3]}&lt;br&gt;' +\n                  'Número de Programas: %{customdata[4]}&lt;br&gt;' +\n                  '&lt;extra&gt;&lt;/extra&gt;'\n) \n# Mostramos o gráfico:\nfig.show()"
  },
  {
    "objectID": "sucupira-baixando.html",
    "href": "sucupira-baixando.html",
    "title": "Obtendo dados submetidos à Plataforma Sucupira",
    "section": "",
    "text": "Atenção!\n\n\n\nEsta seção trata de dados que só podem ser obtidos da Plataforma Sucupira com credenciais de coordenador de programa de pós-graduação!",
    "crumbs": [
      "Dados do Coleta",
      "Obtendo os dados"
    ]
  },
  {
    "objectID": "sucupira-baixando.html#como-obter-os-dados",
    "href": "sucupira-baixando.html#como-obter-os-dados",
    "title": "Obtendo dados submetidos à Plataforma Sucupira",
    "section": "Como obter os dados",
    "text": "Como obter os dados\nPara as análises nesta seção usaremos os dados submetidos à Plataforma Sucupira (não os dados abertos da CAPES, que serão usados em outra seção), mas somente os dados de um determinado programa de pós-graduação. Estes dados podem ser obtidos no próprio módulo de coleta de dados, acessível somente por coordenadores deste programa e pessoas autorizadas.\nPara obter estes dados é necessário entrar na Plataforma Sucupira e clique em ACESSO RESTRITO, depois no ícone do Portal do Coordenador de PPG.\nOs dados que já foram enviados pela plataforma e homologados pelas pró-reitorias podem ser baixados na forma de planilhas. Use o menu Coleta Online/Relatórios/Dados Enviados do Coleta conforme mostrado na imagem a seguir.\n\nO portal mostrará opções para selecionar o ano de envio dos dados, opções para escolher quais categorias de dados devem ser baixados e o formato como mostrado a seguir.\n\nEscolha o ano, selecione todos os dados e escolha XLS como formato de exportação. Clique em Gerar Relatório e aguarde alguns segundos par ver o link para obtenção do arquivo. Repita esta operação para cada ano que quiser analisar, renomeando o arquivo baixado.\n\nArquivos baixados neste exemplo\nPara os exemplos usados nestes documentos a lista de arquivos, já renomeada, é:\nrelatorio_dados_enviados_coleta_2014.xlsx\nrelatorio_dados_enviados_coleta_2015.xlsx\nrelatorio_dados_enviados_coleta_2016.xlsx\nrelatorio_dados_enviados_coleta_2017.xlsx\nrelatorio_dados_enviados_coleta_2018.xlsx\nrelatorio_dados_enviados_coleta_2019.xlsx\nrelatorio_dados_enviados_coleta_2020.xlsx\nrelatorio_dados_enviados_coleta_2021.xlsx\nrelatorio_dados_enviados_coleta_2022.xlsx\nrelatorio_dados_enviados_coleta_2023.xlsx\n\n\nDados do preenchimento do ano corrente\nAs planilhas baixadas através do procedimento mostrado na seção anterior contém dados que já foram enviados para a CAPES, mas não os dados sendo preenchidos no ano corrente. Se for necessário baixar alguns dos dados do preenchimento podemos fazê-lo para algumas categorias.\nÉ importante observar que a planilha com dados do ano corrente tem formato e conteúdo diferente das planilhas dos anos já homologados.\nComo veremos alguns exemplos de análise de publicações vamos baixar a planilha de publicações do ano corrente. Acesse, no Portal do Coordenador de PPG da Plataforma Sucupira, o menu Coleta Online/Relatórios/Conferência do Programa, como ilustrado na figura abaixo:\n Para baixar a planilha com dados de publicações do ano corrente (claro, somente com as que o coordenador tiver importado ou cadastrado na Plataforma Sucupira) selecione a categoria Produção Intelectual, use como Ano de Referência o ano corrente, selecione a opção de exportar relatório para XLS e como tipo de relatório selecione Lista replicada de produções intelectuais com informação de autores – esta será a opção mais adequada para os relatórios deste estudo. As opções sugeridas são mostradas na figura abaixo.\n\nClique em Gerar Relatório e aguarde o link para baixar a planilha. Renomeie-a para ListaReplicadaComAutores.xls.\n\n\n\n\n\n\nNota\n\n\n\nÉ possível obter esta planilha mesmo após a submissão e homologação do Coleta do ano de referência.",
    "crumbs": [
      "Dados do Coleta",
      "Obtendo os dados"
    ]
  },
  {
    "objectID": "dados-ibge.html",
    "href": "dados-ibge.html",
    "title": "Dados do IBGE",
    "section": "",
    "text": "Outras fontes de dados podem ajudar em algumas análises. Nesta seção veremos como recuperar e preprocessar dados do Sistema IBGE de Recuperação Automática - SIDRA.\nNo Sistema Sidra, opção Acervo, podemos obter uma grande variedade de planilhas com dados socioeconômicos. A interface de busca e filtros é mostrada na figura abaixo:\n\nPara as análises que queremos demonstrar usaremos duas planilhas:\n\nUsando os filtros IO - Produto Interno Bruto dos Municípios e 81 - Contas Nacionais e Regionais baixamos a planilha Tabela 5938 - Produto interno bruto a preços correntes, impostos, líquidos de subsídios, sobre produtos a preços correntes e valor adicionado bruto a preços correntes total e por atividade econômica, e respectivas participações.  Para esta planilha somente é possível obter dados de 2021, mas servem para as nossas análises e gráficos.\nUsando os filtros C2 - Objetivos de Desenvolvimento Sustentável e 304 - Erradicação da pobreza baixamos a planilha Tabela 5817 - Indicador 1.1.1 - Proporção da população abaixo da linha de pobreza internacional para o ano de 2022.\nUsando os filtros C2 - Objetivos de Desenvolvimento Sustentável e 27 - Educação baixamos a planilha Tabela 7783 - Indicador 4.a.1 - Proporção de escolas dos anos iniciais e finais do ensino fundamental, do ensino médio, por infraestrutura das escolas para o ano de 2022, considerando somente o número de escolhas de ensino médio por estado.\nUsando os filtros CD - Censo Demográfico e 52 - Pessoas baixamos a planilha Tabela 1209 - População, por grupos de idade para o ano de 2022.\n\n\n\n\n\n\n\nNota\n\n\n\nOs links acima levam para páginas que contém outras bases de dados associadas. Procure pelos números das planilhas caso queira baixá-las novamente. Outros passos poderão ser necessários (ex. para selecionar anos e outras informações) – no caso escolhi baixar planilhas preparadas com dados de cada unidade federativa.\n\n\n\n\nAs planilhas baixadas devem ser preprocessadas para conter somente os dados que precisamos (ex. eliminando cabeçalhos e rodapés). Podemos fazer isto em poucas linhas de código, primeiro importando as bibliotecas necessárias:\n\nimport pandas as pd\nimport re\nimport warnings\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nVamos criar um dataframe base com informações sobre cada estado brasileiro. A área também foi obtida no site do IBGE.\n\n# Criamos um dicionário de nomes, siglas e áreas dos estados:\ndata = [\n    {'Estado': 'Acre', 'Sigla': 'AC', 'Área': 164173.429},\n    {'Estado': 'Alagoas', 'Sigla': 'AL', 'Área': 27830.661},\n    {'Estado': 'Amapá', 'Sigla': 'AP', 'Área': 142470.762},\n    {'Estado': 'Amazonas', 'Sigla': 'AM', 'Área': 1559255.881},\n    {'Estado': 'Bahia', 'Sigla': 'BA', 'Área': 564760.429},\n    {'Estado': 'Ceará', 'Sigla': 'CE', 'Área': 148894.447},\n    {'Estado': 'Distrito Federal', 'Sigla': 'DF', 'Área': 5760.784},\n    {'Estado': 'Espírito Santo', 'Sigla': 'ES', 'Área': 46074.448},\n    {'Estado': 'Goiás', 'Sigla': 'GO', 'Área': 340242.859},\n    {'Estado': 'Maranhão', 'Sigla': 'MA', 'Área': 329651.496},\n    {'Estado': 'Mato Grosso', 'Sigla': 'MT', 'Área': 903208.361},\n    {'Estado': 'Mato Grosso do Sul', 'Sigla': 'MS', 'Área': 357142.082},\n    {'Estado': 'Minas Gerais', 'Sigla': 'MG', 'Área': 586513.983},\n    {'Estado': 'Pará', 'Sigla': 'PA', 'Área': 1245870.704},\n    {'Estado': 'Paraíba', 'Sigla': 'PB', 'Área': 56467.242},\n    {'Estado': 'Paraná', 'Sigla': 'PR', 'Área': 199298.981},\n    {'Estado': 'Pernambuco', 'Sigla': 'PE', 'Área': 98067.877},\n    {'Estado': 'Piauí', 'Sigla': 'PI', 'Área': 251755.481},\n    {'Estado': 'Rio de Janeiro', 'Sigla': 'RJ', 'Área': 43750.425},\n    {'Estado': 'Rio Grande do Norte', 'Sigla': 'RN', 'Área': 52809.599},\n    {'Estado': 'Rio Grande do Sul', 'Sigla': 'RS', 'Área': 281707.151},\n    {'Estado': 'Rondônia', 'Sigla': 'RO', 'Área': 237754.172},\n    {'Estado': 'Roraima', 'Sigla': 'RR', 'Área': 223644.53},\n    {'Estado': 'Santa Catarina', 'Sigla': 'SC', 'Área': 95730.69},\n    {'Estado': 'São Paulo', 'Sigla': 'SP', 'Área': 248219.485},\n    {'Estado': 'Sergipe', 'Sigla': 'SE', 'Área': 21938.188},\n    {'Estado': 'Tocantins', 'Sigla': 'TO', 'Área': 277423.627}\n]\n# Criamos nosso dataframe a partir do dicionário:\ndfBase = pd.DataFrame(data)\n\n\n\n\nVamos agora ler a planilha com dados sobre o PIB, renomeando suas colunas para facilitar a manipulação:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfPIB = pd.read_excel('Resources/Data/OutrosDados/tabela5938.xlsx')\n    dfPIB.columns = ['Estado', 'PIB']\n\nVamos também criar um dataframe a partir da planilha com dados sobre a proporção da população abaixo da linha de pobreza internacional:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfPALB = pd.read_excel('Resources/Data/OutrosDados/tabela5817.xlsx')\n    dfPALB.columns = ['Estado', 'PALB']\n\nFinalmente vamos criar um dataframe a partir da planilha com o número de escolas de ensino médio:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfEEM = pd.read_excel('Resources/Data/OutrosDados/tabela7783.xlsx')\n    dfEEM.columns = ['Estado', 'Infraestrutura','EEM']\n# Não precisamos da coluna 'Infraestrutura':\ndfEEM = dfEEM.drop(columns=['Infraestrutura'])\n\nPodemos então unir os dataframes usando o campo Estado como chave. Basicamente a união juntará duas planilhas baseado no valor da coluna Estado, evitando trazer valores onde não exista correspondência.\n\nunião = pd.merge(dfBase, dfPIB, on='Estado', how='left')\nunião = pd.merge(união, dfPALB, on='Estado', how='left')\nunião = pd.merge(união, dfEEM, on='Estado', how='left')\n\nMostramos o resultado como uma tabela:\n\nMarkdown(tabulate(\n  união, \n  headers=[\"Estado\",\"Sigla\",\"PIB\",\"% Abaixo Linha Pobreza\",\"EEM\"],\n  showindex=False,\n))\n\n\n\n\n\nEstado\nSigla\nPIB\n% Abaixo Linha Pobreza\nEEM\n\n\n\n\nAcre\nAC\n164173\n21374440\n14\n278\n\n\nAlagoas\nAL\n27830.7\n76265620\n13.1\n410\n\n\nAmapá\nAP\n142471\n20099851\n7.9\n159\n\n\nAmazonas\nAM\n1.55926e+06\n131531038\n10.5\n501\n\n\nBahia\nBA\n564760\n352617852\n11.9\n1559\n\n\nCeará\nCE\n148894\n194884802\n10.9\n984\n\n\nDistrito Federal\nDF\n5760.78\n286943782\n1.8\n263\n\n\nEspírito Santo\nES\n46074.4\n186336505\n4.1\n431\n\n\nGoiás\nGO\n340243\n269627874\n2.7\n1063\n\n\nMaranhão\nMA\n329651\n124980720\n15\n1044\n\n\nMato Grosso\nMT\n903208\n233390203\n4.1\n686\n\n\nMato Grosso do Sul\nMS\n357142\n142203766\n2.7\n444\n\n\nMinas Gerais\nMG\n586514\n857593214\n3.2\n3288\n\n\nPará\nPA\n1.24587e+06\n262904979\n7.5\n891\n\n\nParaíba\nPB\n56467.2\n77470331\n11.1\n658\n\n\nParaná\nPR\n199299\n549973062\n2.9\n2052\n\n\nPernambuco\nPE\n98067.9\n220813522\n11.7\n1124\n\n\nPiauí\nPI\n251755\n64028303\n11.6\n654\n\n\nRio de Janeiro\nRJ\n43750.4\n949300770\n4.5\n2324\n\n\nRio Grande do Norte\nRN\n52809.6\n80180733\n9.4\n474\n\n\nRio Grande do Sul\nRS\n281707\n581283677\n2.5\n1539\n\n\nRondônia\nRO\n237754\n58170096\n4.3\n248\n\n\nRoraima\nRR\n223645\n18202579\n7.8\n173\n\n\nSanta Catarina\nSC\n95730.7\n428570889\n1.8\n1027\n\n\nSão Paulo\nSP\n248219\n2719751231\n2.9\n6480\n\n\nSergipe\nSE\n21938.2\n51861397\n8.9\n304\n\n\nTocantins\nTO\n277424\n51780764\n4.9\n355\n\n\n\n\n\nSalvamos esta base para uso posterior:\n\nunião.to_csv(\"Resources/Data/OutrosDados/DadosIBGE.csv\",index=False) \n\n\n\n\nA planilha com dados sobre a população por grupos de idade deve ser processada de forma diferente, uma vez que contém vários campos por estado. Vamos pular os cabeçalhos e total de população para o Brasil e ajustar os nomes dos campos manualmente:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfPOP = pd.read_excel('Resources/Data/OutrosDados/tabela1209.xlsx',\n                          skiprows=18, header=None)\n# Ajustamos os nomes dos campos.  \ndfPOP.columns = ['Estado', 'Ano', 'Grupo de Idade', 'População']\n# Como só usaremos um ano não precisamos daquela coluna.\ndfPOP = dfPOP.drop(columns=['Ano'])\n\nPor causa do formato da planilha original, o nome do estado só aparece na primeira linha de seu bloco de informações. Podemos resolver isto facilmente com um preenchimento para frente de valores ausentes:\n\ndfPOP['Estado'] = dfPOP['Estado'].ffill()\n\nAgora precisamos reordenar a planilha para que cada um dos valores da coluna ‘Grupo de Idade’ vire uma nova coluna:\n\nreordenada = dfPOP.pivot_table(index=['Estado'], columns='Grupo de Idade', \n                               values='População', aggfunc='first').reset_index()\n\nQuando os dados da planilha são reordenados a ordem para as colunas não é a ideal: alguns valores são considerados numéricos e gostaríamos que a coluna Total fosse a primeira depois de Estado. Para reordenar podemos criar uma ordem explícita:\n\n# Define a custom order for the age range columns\nordemFaixas = [\n    'Total',\n    '0 a 4 anos',\n    '5 a 9 anos',\n    '10 a 14 anos',\n    '15 a 17 anos',\n    '15 a 19 anos',\n    '18 e 19 anos',\n    '20 a 24 anos',\n    '25 a 29 anos',\n    '30 a 39 anos',\n    '40 a 49 anos',\n    '50 a 59 anos',\n    '60 a 69 anos',\n    '70 anos ou mais',\n    'Idade ignorada'\n]\n\nBasta criar um subset do dataframe com as colunas na ordem que queremos:\n\ncolunasEmOrdem= ['Estado'] + [col for col in ordemFaixas if col in reordenada.columns]\nreordenada = reordenada[colunasEmOrdem]\n\nEsta planilha tem uma coluna redundante: 15 a 19 anos, que é a soma das colunas 15 a 17 anos e 18 e 19 anos. Vamos eliminar a redundante para simplificar.\n\nreordenada = reordenada.drop(columns=['15 a 19 anos'])\n\nVamos unir este dataframe com o de base, com nomes dos estados e suas áreas.\n\nunião = pd.merge(dfBase, reordenada, on='Estado', how='left')\n\nVamos salvar este dataframe para uso posterior.\n\nunião.to_csv(\"Resources/Data/OutrosDados/IBGEPopulação.csv\",index=False)"
  },
  {
    "objectID": "dados-ibge.html#sobre",
    "href": "dados-ibge.html#sobre",
    "title": "Dados do IBGE",
    "section": "",
    "text": "Outras fontes de dados podem ajudar em algumas análises. Nesta seção veremos como recuperar e preprocessar dados do Sistema IBGE de Recuperação Automática - SIDRA.\nNo Sistema Sidra, opção Acervo, podemos obter uma grande variedade de planilhas com dados socioeconômicos. A interface de busca e filtros é mostrada na figura abaixo:\n\nPara as análises que queremos demonstrar usaremos duas planilhas:\n\nUsando os filtros IO - Produto Interno Bruto dos Municípios e 81 - Contas Nacionais e Regionais baixamos a planilha Tabela 5938 - Produto interno bruto a preços correntes, impostos, líquidos de subsídios, sobre produtos a preços correntes e valor adicionado bruto a preços correntes total e por atividade econômica, e respectivas participações.  Para esta planilha somente é possível obter dados de 2021, mas servem para as nossas análises e gráficos.\nUsando os filtros C2 - Objetivos de Desenvolvimento Sustentável e 304 - Erradicação da pobreza baixamos a planilha Tabela 5817 - Indicador 1.1.1 - Proporção da população abaixo da linha de pobreza internacional para o ano de 2022.\nUsando os filtros C2 - Objetivos de Desenvolvimento Sustentável e 27 - Educação baixamos a planilha Tabela 7783 - Indicador 4.a.1 - Proporção de escolas dos anos iniciais e finais do ensino fundamental, do ensino médio, por infraestrutura das escolas para o ano de 2022, considerando somente o número de escolhas de ensino médio por estado.\nUsando os filtros CD - Censo Demográfico e 52 - Pessoas baixamos a planilha Tabela 1209 - População, por grupos de idade para o ano de 2022.\n\n\n\n\n\n\n\nNota\n\n\n\nOs links acima levam para páginas que contém outras bases de dados associadas. Procure pelos números das planilhas caso queira baixá-las novamente. Outros passos poderão ser necessários (ex. para selecionar anos e outras informações) – no caso escolhi baixar planilhas preparadas com dados de cada unidade federativa.\n\n\n\n\nAs planilhas baixadas devem ser preprocessadas para conter somente os dados que precisamos (ex. eliminando cabeçalhos e rodapés). Podemos fazer isto em poucas linhas de código, primeiro importando as bibliotecas necessárias:\n\nimport pandas as pd\nimport re\nimport warnings\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\n\nVamos criar um dataframe base com informações sobre cada estado brasileiro. A área também foi obtida no site do IBGE.\n\n# Criamos um dicionário de nomes, siglas e áreas dos estados:\ndata = [\n    {'Estado': 'Acre', 'Sigla': 'AC', 'Área': 164173.429},\n    {'Estado': 'Alagoas', 'Sigla': 'AL', 'Área': 27830.661},\n    {'Estado': 'Amapá', 'Sigla': 'AP', 'Área': 142470.762},\n    {'Estado': 'Amazonas', 'Sigla': 'AM', 'Área': 1559255.881},\n    {'Estado': 'Bahia', 'Sigla': 'BA', 'Área': 564760.429},\n    {'Estado': 'Ceará', 'Sigla': 'CE', 'Área': 148894.447},\n    {'Estado': 'Distrito Federal', 'Sigla': 'DF', 'Área': 5760.784},\n    {'Estado': 'Espírito Santo', 'Sigla': 'ES', 'Área': 46074.448},\n    {'Estado': 'Goiás', 'Sigla': 'GO', 'Área': 340242.859},\n    {'Estado': 'Maranhão', 'Sigla': 'MA', 'Área': 329651.496},\n    {'Estado': 'Mato Grosso', 'Sigla': 'MT', 'Área': 903208.361},\n    {'Estado': 'Mato Grosso do Sul', 'Sigla': 'MS', 'Área': 357142.082},\n    {'Estado': 'Minas Gerais', 'Sigla': 'MG', 'Área': 586513.983},\n    {'Estado': 'Pará', 'Sigla': 'PA', 'Área': 1245870.704},\n    {'Estado': 'Paraíba', 'Sigla': 'PB', 'Área': 56467.242},\n    {'Estado': 'Paraná', 'Sigla': 'PR', 'Área': 199298.981},\n    {'Estado': 'Pernambuco', 'Sigla': 'PE', 'Área': 98067.877},\n    {'Estado': 'Piauí', 'Sigla': 'PI', 'Área': 251755.481},\n    {'Estado': 'Rio de Janeiro', 'Sigla': 'RJ', 'Área': 43750.425},\n    {'Estado': 'Rio Grande do Norte', 'Sigla': 'RN', 'Área': 52809.599},\n    {'Estado': 'Rio Grande do Sul', 'Sigla': 'RS', 'Área': 281707.151},\n    {'Estado': 'Rondônia', 'Sigla': 'RO', 'Área': 237754.172},\n    {'Estado': 'Roraima', 'Sigla': 'RR', 'Área': 223644.53},\n    {'Estado': 'Santa Catarina', 'Sigla': 'SC', 'Área': 95730.69},\n    {'Estado': 'São Paulo', 'Sigla': 'SP', 'Área': 248219.485},\n    {'Estado': 'Sergipe', 'Sigla': 'SE', 'Área': 21938.188},\n    {'Estado': 'Tocantins', 'Sigla': 'TO', 'Área': 277423.627}\n]\n# Criamos nosso dataframe a partir do dicionário:\ndfBase = pd.DataFrame(data)\n\n\n\n\nVamos agora ler a planilha com dados sobre o PIB, renomeando suas colunas para facilitar a manipulação:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfPIB = pd.read_excel('Resources/Data/OutrosDados/tabela5938.xlsx')\n    dfPIB.columns = ['Estado', 'PIB']\n\nVamos também criar um dataframe a partir da planilha com dados sobre a proporção da população abaixo da linha de pobreza internacional:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfPALB = pd.read_excel('Resources/Data/OutrosDados/tabela5817.xlsx')\n    dfPALB.columns = ['Estado', 'PALB']\n\nFinalmente vamos criar um dataframe a partir da planilha com o número de escolas de ensino médio:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfEEM = pd.read_excel('Resources/Data/OutrosDados/tabela7783.xlsx')\n    dfEEM.columns = ['Estado', 'Infraestrutura','EEM']\n# Não precisamos da coluna 'Infraestrutura':\ndfEEM = dfEEM.drop(columns=['Infraestrutura'])\n\nPodemos então unir os dataframes usando o campo Estado como chave. Basicamente a união juntará duas planilhas baseado no valor da coluna Estado, evitando trazer valores onde não exista correspondência.\n\nunião = pd.merge(dfBase, dfPIB, on='Estado', how='left')\nunião = pd.merge(união, dfPALB, on='Estado', how='left')\nunião = pd.merge(união, dfEEM, on='Estado', how='left')\n\nMostramos o resultado como uma tabela:\n\nMarkdown(tabulate(\n  união, \n  headers=[\"Estado\",\"Sigla\",\"PIB\",\"% Abaixo Linha Pobreza\",\"EEM\"],\n  showindex=False,\n))\n\n\n\n\n\nEstado\nSigla\nPIB\n% Abaixo Linha Pobreza\nEEM\n\n\n\n\nAcre\nAC\n164173\n21374440\n14\n278\n\n\nAlagoas\nAL\n27830.7\n76265620\n13.1\n410\n\n\nAmapá\nAP\n142471\n20099851\n7.9\n159\n\n\nAmazonas\nAM\n1.55926e+06\n131531038\n10.5\n501\n\n\nBahia\nBA\n564760\n352617852\n11.9\n1559\n\n\nCeará\nCE\n148894\n194884802\n10.9\n984\n\n\nDistrito Federal\nDF\n5760.78\n286943782\n1.8\n263\n\n\nEspírito Santo\nES\n46074.4\n186336505\n4.1\n431\n\n\nGoiás\nGO\n340243\n269627874\n2.7\n1063\n\n\nMaranhão\nMA\n329651\n124980720\n15\n1044\n\n\nMato Grosso\nMT\n903208\n233390203\n4.1\n686\n\n\nMato Grosso do Sul\nMS\n357142\n142203766\n2.7\n444\n\n\nMinas Gerais\nMG\n586514\n857593214\n3.2\n3288\n\n\nPará\nPA\n1.24587e+06\n262904979\n7.5\n891\n\n\nParaíba\nPB\n56467.2\n77470331\n11.1\n658\n\n\nParaná\nPR\n199299\n549973062\n2.9\n2052\n\n\nPernambuco\nPE\n98067.9\n220813522\n11.7\n1124\n\n\nPiauí\nPI\n251755\n64028303\n11.6\n654\n\n\nRio de Janeiro\nRJ\n43750.4\n949300770\n4.5\n2324\n\n\nRio Grande do Norte\nRN\n52809.6\n80180733\n9.4\n474\n\n\nRio Grande do Sul\nRS\n281707\n581283677\n2.5\n1539\n\n\nRondônia\nRO\n237754\n58170096\n4.3\n248\n\n\nRoraima\nRR\n223645\n18202579\n7.8\n173\n\n\nSanta Catarina\nSC\n95730.7\n428570889\n1.8\n1027\n\n\nSão Paulo\nSP\n248219\n2719751231\n2.9\n6480\n\n\nSergipe\nSE\n21938.2\n51861397\n8.9\n304\n\n\nTocantins\nTO\n277424\n51780764\n4.9\n355\n\n\n\n\n\nSalvamos esta base para uso posterior:\n\nunião.to_csv(\"Resources/Data/OutrosDados/DadosIBGE.csv\",index=False) \n\n\n\n\nA planilha com dados sobre a população por grupos de idade deve ser processada de forma diferente, uma vez que contém vários campos por estado. Vamos pular os cabeçalhos e total de população para o Brasil e ajustar os nomes dos campos manualmente:\n\n# Evitamos mensagens sobre importação de planilhas.\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=UserWarning, \n                            module=re.escape('openpyxl.styles.stylesheet'))\n    dfPOP = pd.read_excel('Resources/Data/OutrosDados/tabela1209.xlsx',\n                          skiprows=18, header=None)\n# Ajustamos os nomes dos campos.  \ndfPOP.columns = ['Estado', 'Ano', 'Grupo de Idade', 'População']\n# Como só usaremos um ano não precisamos daquela coluna.\ndfPOP = dfPOP.drop(columns=['Ano'])\n\nPor causa do formato da planilha original, o nome do estado só aparece na primeira linha de seu bloco de informações. Podemos resolver isto facilmente com um preenchimento para frente de valores ausentes:\n\ndfPOP['Estado'] = dfPOP['Estado'].ffill()\n\nAgora precisamos reordenar a planilha para que cada um dos valores da coluna ‘Grupo de Idade’ vire uma nova coluna:\n\nreordenada = dfPOP.pivot_table(index=['Estado'], columns='Grupo de Idade', \n                               values='População', aggfunc='first').reset_index()\n\nQuando os dados da planilha são reordenados a ordem para as colunas não é a ideal: alguns valores são considerados numéricos e gostaríamos que a coluna Total fosse a primeira depois de Estado. Para reordenar podemos criar uma ordem explícita:\n\n# Define a custom order for the age range columns\nordemFaixas = [\n    'Total',\n    '0 a 4 anos',\n    '5 a 9 anos',\n    '10 a 14 anos',\n    '15 a 17 anos',\n    '15 a 19 anos',\n    '18 e 19 anos',\n    '20 a 24 anos',\n    '25 a 29 anos',\n    '30 a 39 anos',\n    '40 a 49 anos',\n    '50 a 59 anos',\n    '60 a 69 anos',\n    '70 anos ou mais',\n    'Idade ignorada'\n]\n\nBasta criar um subset do dataframe com as colunas na ordem que queremos:\n\ncolunasEmOrdem= ['Estado'] + [col for col in ordemFaixas if col in reordenada.columns]\nreordenada = reordenada[colunasEmOrdem]\n\nEsta planilha tem uma coluna redundante: 15 a 19 anos, que é a soma das colunas 15 a 17 anos e 18 e 19 anos. Vamos eliminar a redundante para simplificar.\n\nreordenada = reordenada.drop(columns=['15 a 19 anos'])\n\nVamos unir este dataframe com o de base, com nomes dos estados e suas áreas.\n\nunião = pd.merge(dfBase, reordenada, on='Estado', how='left')\n\nVamos salvar este dataframe para uso posterior.\n\nunião.to_csv(\"Resources/Data/OutrosDados/IBGEPopulação.csv\",index=False)"
  },
  {
    "objectID": "dadosabertos-baixando.html",
    "href": "dadosabertos-baixando.html",
    "title": "Obtendo dados abertos da CAPES",
    "section": "",
    "text": "Atenção!\n\n\n\nOs dados usados nesta seção podem ser baixados por qualquer usuário a partir do portal de dados abertos da CAPES."
  },
  {
    "objectID": "dadosabertos-baixando.html#sec-dados-abertos-obter",
    "href": "dadosabertos-baixando.html#sec-dados-abertos-obter",
    "title": "Obtendo dados abertos da CAPES",
    "section": "Como obter os dados",
    "text": "Como obter os dados\nA CAPES (Coordenação de Aperfeiçoamento de Pessoal de Nível Superior) mantém várias coleções temáticas de dados abertos que podem ser usados para pesquisa. Alguns destes dados são alimentados pela Plataforma Sucupira e contém informações sobre todos os programas de pós-graduação stricto sensu do Brasil.\nPor usar como fonte a Plataforma Sucupira os conjuntos de dados nas coleções cobrem até a última avaliação anual: em Maio de 2024, somente os dados até 2022 estavam disponíveis.\nPara acessar as coleções vá ao portal Dados Abertos CAPES. No portal são listados vários temas, como mostrados na figura abaixo.\n\nPara as análises deste documento vamos usar o tema Avaliação da Pós-Graduação Stricto Sensu:\n\nSelecionando esta opção aparecerá uma página onde podemos selecionar os conjuntos de dados por categoria ou filtrando por palavra-chave. Ao fazer uma busca ou seleção aparecerão descritores dos conjuntos, identificados por título e período de cobertura, como mostrado a seguir.\n\nAo clicar em um dos descritores veremos outra página com todos os arquivos daquela coleção, com links para baixar os arquivos.\nVejam que um conjunto de dados pode estar distribuído em várias páginas (por exemplo, dados de cursos estão nas páginas [2013 a 2016] Cursos da Pós-Graduação Stricto Sensu do Brasil, [2017 a 2020] Cursos da Pós-Graduação Stricto Sensu no Brasil e [2021 a 2024] Cursos da Pós-Graduação Stricto Sensu no Brasil, dados da Produção Intelectual estão distribuídos em nove páginas). Como os arquivos variam de acordo com a coleção veremos quais baixar nos exemplos específicos a seguir."
  },
  {
    "objectID": "dadosabertos-baixando.html#sec-dados-abertos-cursos",
    "href": "dadosabertos-baixando.html#sec-dados-abertos-cursos",
    "title": "Obtendo dados abertos da CAPES",
    "section": "Dados sobre Cursos da Pós-Graduação Stricto Sensu no Brasil",
    "text": "Dados sobre Cursos da Pós-Graduação Stricto Sensu no Brasil\nVamos começar baixando as planilhas com os dados dos cursos de pós-graduação. Elas estão distribuídas em três páginas no Portal de Dados Abertos: [2013 a 2016] Cursos da Pós-Graduação Stricto Sensu do Brasil, [2017 a 2020] Cursos da Pós-Graduação Stricto Sensu no Brasil e [2021 a 2024] Cursos da Pós-Graduação Stricto Sensu no Brasil. Cada página contém links para baixar as planilhas nos formatos .csv e .xlsx, para cada um dos anos da coleção, além de arquivos com metadados. A figura abaixo mostra os links para acesso às planilhas com dados entre 2013 e 2016.\n\nPara as nossas análises vamos usar os arquivos .xlsx, que podem ser baixados clicando nos ícones verdes com uma seta para baixo e aguardar o início do download. Os arquivos baixados são mostrados a seguir:\n\n\n\nTabela 1: Arquivos com dados sobre cursos\n\n\n\n\n\n\n\n\n\n\n\nNome do arquivo\nTamanho\nColunas\nLinhas\n\n\n\n\nbr-capes-colsucup-curso-2013a2016-2020-06-12_2013.xlsx\n792012\n28\n5646\n\n\nbr-capes-colsucup-curso-2013a2016-2020-06-12_2014.xlsx\n821140\n28\n5854\n\n\nbr-capes-colsucup-curso-2013a2016-2020-06-12_2015.xlsx\n854794\n28\n6060\n\n\nbr-capes-colsucup-curso-2013a2016-2020-06-12_2016.xlsx\n890656\n28\n6313\n\n\nbr-capes-colsucup-curso-2017-2021-11-10.xlsx\n923526\n28\n6494\n\n\nbr-capes-colsucup-curso-2018-2021-11-10.xlsx\n950909\n28\n6695\n\n\nbr-capes-colsucup-curso-2019-2021-11-10.xlsx\n991420\n28\n6950\n\n\nbr-capes-colsucup-curso-2020-2021-11-10.xlsx\n995363\n28\n7000\n\n\nbr-capes-colsucup-curso-2021-2023-11-30.xlsx\n1021464\n28\n7163\n\n\nbr-capes-colsucup-curso-2022-2023-11-30.xlsx\n1001124\n28\n7027"
  },
  {
    "objectID": "dadosabertos-baixando.html#sec-dados-abertos-docentes",
    "href": "dadosabertos-baixando.html#sec-dados-abertos-docentes",
    "title": "Obtendo dados abertos da CAPES",
    "section": "Dados sobre Docentes da Pós-Graduação Stricto Sensu no Brasil",
    "text": "Dados sobre Docentes da Pós-Graduação Stricto Sensu no Brasil\nVamos também baixar as planilhas com os dados dos docentes de pós-graduação. Elas estão distribuídas em quatro páginas no Portal de Dados Abertos: [2004 a 2012] Docentes dos Programas de Pós-Graduação stricto sensu no Brasil, [2013 a 2016] Docentes da Pós-Graduação Stricto Sensu no Brasil, [2017 a 2020] Docentes da Pós-Graduação Stricto Sensu no Brasil e [2021 a 2024] Docentes da Pós-Graduação Stricto Sensu no Brasil. Cada página contém links para baixar as planilhas nos formatos .csv e .xlsx, para cada um dos anos da coleção, além de arquivos com metadados. A figura abaixo mostra os links para acesso às planilhas com dados entre 2004 e 2012.\n\nOs arquivos baixados, seus tamanhos em bytes, e suas quantidades de colunas e linhas (sem cabeçalho) são mostrados na tabela a seguir.\n\n\n\nTabela 2: Arquivos com dados sobre docentes\n\n\n\n\n\n\n\n\n\n\n\nNome do arquivo\nTamanho\nColunas\nLinhas\n\n\n\n\nbr-capes-colsucup-docente-2004a2012-2021-03-01.xlsx\n65227884\n33\n491773\n\n\nbr-capes-colsucup-docente-2013-2023-08-01.xlsx\n13784386\n42\n79622\n\n\nbr-capes-colsucup-docente-2014-2023-08-01.xlsx\n14842064\n42\n85650\n\n\nbr-capes-colsucup-docente-2015-2023-08-01.xlsx\n15626101\n42\n90307\n\n\nbr-capes-colsucup-docente-2016-2023-08-01.xlsx\n16477872\n42\n95246\n\n\nbr-capes-colsucup-docente-2017-2021-11-10.xlsx\n19000457\n41\n102279\n\n\nbr-capes-colsucup-docente-2018-2021-11-10.xlsx\n19435907\n41\n104531\n\n\nbr-capes-colsucup-docente-2019-2021-11-10.xlsx\n20148746\n41\n108346\n\n\nbr-capes-colsucup-docente-2020-2021-11-10.xlsx\n19782331\n41\n105575\n\n\nbr-capes-colsucup-docente-2021-2023-11-30.xlsx\n20025270\n41\n110059\n\n\nbr-capes-colsucup-docente-2022-2023-11-30.xlsx\n20267644\n41\n109548"
  },
  {
    "objectID": "dadosabertos-baixando.html#sec-dados-abertos-discentes",
    "href": "dadosabertos-baixando.html#sec-dados-abertos-discentes",
    "title": "Obtendo dados abertos da CAPES",
    "section": "Dados sobre Discentes da Pós-Graduação Stricto Sensu no Brasil",
    "text": "Dados sobre Discentes da Pós-Graduação Stricto Sensu no Brasil\nO Portal de Dados Abertos também contém informações detalhadas sobre todos os discentes dos programas de pós-graduação stricto sensu do Brasil, organizados em planilhas, uma por ano, e separadas em vários grupos, cada um com sua página de acesso, em um total de quatro páginas. A figura abaixo mostra os links para acesso às planilhas com dados entre 2021 e 2024.\n\nVejam que apesar do conjunto de dados fazer referência aos anos 2021 a 2024, somente estão presentes links para 2021 e 2022, por causa dos prazos da coleta na Plataforma Sucupira (leiam sempre a descrição sobre o conjunto no portal!)\nDependendo da análise basta baixar os arquivos correspondentes aos anos de interesse, mas para completude e para ilustrar casos difíceis no preprocessamento vamos baixar todas as planilhas disponíveis. Para isto será necessário acessar também os conjuntos de dados [2004 a 2012] Discentes dos Programas de Pós-Graduação stricto sensu no Brasil, [2013 a 2016] Discentes da Pós-Graduação Stricto Sensu do Brasil e [2017 a 2020] Discentes da Pós-Graduação stricto sensu do Brasil.\nOs arquivos baixados, seus tamanhos em bytes, e suas quantidades de colunas e linhas (sem cabeçalho) são mostrados na tabela a seguir.\n\n\n\nTabela 3: Arquivos com dados sobre discentes\n\n\n\n\n\n\n\n\n\n\n\nNome do arquivo\nTamanho\nColunas\nLinhas\n\n\n\n\nbr-capes-colsucup-discentes-2004-2021-03-01.xlsx\n26195517\nAE (31)\n190038\n\n\nbr-capes-colsucup-discentes-2005-2021-03-01.xlsx\n29273270\nAE (31)\n212073\n\n\nbr-capes-colsucup-discentes-2006-2021-03-01.xlsx\n31559779\nAE (31)\n229290\n\n\nbr-capes-colsucup-discentes-2007-2021-03-01.xlsx\n34804116\nAE (31)\n252102\n\n\nbr-capes-colsucup-discentes-2008-2021-03-01.xlsx\n37449507\nAE (31)\n270170\n\n\nbr-capes-colsucup-discentes-2009-2021-03-01.xlsx\n42033259\nAE (31)\n290592\n\n\nbr-capes-colsucup-discentes-2010-2021-03-01.xlsx\n45629174\nAE (31)\n316398\n\n\nbr-capes-colsucup-discentes-2011-2021-03-01.xlsx\n49755534\nAE (31)\n345048\n\n\nbr-capes-colsucup-discentes-2012-2021-03-01.xlsx\n54409827\nAE (31)\n375260\n\n\nbr-capes-colsucup-discentes-2013-2021-03-01.xlsx\n52967544\nAK (37)\n300210\n\n\nbr-capes-colsucup-discentes-2014-2021-03-01.xlsx\n56048168\nAK (37)\n317846\n\n\nbr-capes-colsucup-discentes-2015-2021-03-01.xlsx\n59802222\nAK (37)\n338035\n\n\nbr-capes-colsucup-discentes-2016-2021-03-01.xlsx\n63325526\nAK (37)\n357353\n\n\nbr-capes-colsucup-discentes-2017-2023-12-01.xlsx\n62190534\nAK (37)\n374429\n\n\nbr-capes-colsucup-discentes-2018-2023-12-01.xlsx\n64833813\nAK (37)\n390174\n\n\nbr-capes-colsucup-discentes-2019-2023-12-01.xlsx\n66848001\nAK (37)\n401311\n\n\nbr-capes-colsucup-discentes-2020-2023-12-01.xlsx\n65222388\nAK (37)\n395870\n\n\nbr-capes-colsucup-discentes-2021-2023-11-30.xlsx\n72086227\nAK (37)\n420350\n\n\nbr-capes-colsucup-discentes-2022-2023-11-30.xlsx\n73083882\nAK (37)\n424081"
  },
  {
    "objectID": "dadosabertos-baixando.html#sec-dados-abertos-producao",
    "href": "dadosabertos-baixando.html#sec-dados-abertos-producao",
    "title": "Obtendo dados abertos da CAPES",
    "section": "Dados sobre Produção Intelectual de Programas de Pós-Graduação Stricto Sensu no Brasil",
    "text": "Dados sobre Produção Intelectual de Programas de Pós-Graduação Stricto Sensu no Brasil\nVamos também baixar alguns dos dados sobre produção intelectual. Esta é a coleção mais complexa e variada dos dados abertos da CAPES, estando representada em três grupos: Produção Intelectual dos Programas de Pós-Graduação Stricto Sensu no Brasil, Autor da Produção Intelectual de Programas de Pós-Graduação Stricto Sensu no Brasil e Detalhes da Produção Intelectual dos Programas da Pós-Graduação Strictu Sensu do Brasil.\nA figura abaixo mostra parte dos links para acesso às planilhas com dados da produção intelectual entre 2021 e 2024.\n\n\n\n\n\n\n\nAtenção!\n\n\n\nCada um dos conjuntos de dados sobre produção intelectual pode ter várias planilhas associadas, correspondentes aos subtipos das produção intelectual. Em alguns casos um tipo e subtipo pode ter duas planilhas associadas, para divisão dos dados, evitando arquivos desnecessariamente grandes.\n\n\nPara os exemplos nas outras seções usaremos somente as produções do tipo técnica e Subtipo Cartas, Mapas ou Similares e do tipo Bibliográfica e Subtipo Artigo em Periódico.\nOs arquivos baixados para produções do tipo técnica e Subtipo Cartas, Mapas ou Similares, seus tamanhos em bytes, e suas quantidades de colunas e linhas (sem cabeçalho) são mostrados na tabela a seguir.\n\n\n\nTabela 4: Arquivos com dados sobre Cartas, Mapas ou Similares\n\n\n\n\n\n\n\n\n\n\n\nNome do arquivo\nTamanho\nColunas\nLinhas\n\n\n\n\nbr-capes-col-prod-2004a2012-2018-08-01-tecnica-cartamap.xlsx\n349520\n31\n2251\n\n\nbr-capes-colsucup-producao-2013a2016-2017-11-01-tecnica-cartamap.xlsx\n224863\n25\n1756\n\n\nbr-capes-colsucup-producao-2017a2020-2022-06-22-tecnica-cartamap.xlsx\n391664\n25\n2914\n\n\nbr-capes-colsucup-producao-2021a2024-2023-10-31-tecnica-cartamap.xlsx\n157706\n29\n1036\n\n\n\n\n\n\nOs arquivos baixados para produções tipo Bibliográfica e Subtipo Artigo em Periódico, seus tamanhos em bytes, e suas quantidades de colunas e linhas (sem cabeçalho) são mostrados na tabela a seguir:\n\n\n\nTabela 5: Arquivos com dados sobre Artigos em Periódicos\n\n\n\n\n\n\n\n\n\n\n\nNome do arquivo\nTamanho\nColunas\nLinhas\n\n\n\n\nbr-capes-col-prod-2004a2012-2018-08-01-bibliografica-artpe.xlsx\n185157864\n31\n1039024\n\n\nbr-capes-colsucup-producao-2013a2016-2020-06-30-bibliografica-artpe.xlsx\n147873130\n29\n849903\n\n\nbr-capes-colsucup-producao-2017a2020-2023-11-30-bibliografica-artpe_parte1.xlsx\n81090821\n29\n581162\n\n\nbr-capes-colsucup-producao-2017a2020-2023-11-30-bibliografica-artpe_parte2.xlsx\n81386085\n29\n581162\n\n\nbr-capes-colsucup-producao-2021a2024-2023-10-31-bibliografica-artpe.xlsx\n92968228\n31\n642735"
  },
  {
    "objectID": "sucupira-preprocessamento.html",
    "href": "sucupira-preprocessamento.html",
    "title": "Pré-Processamento dos Dados da Plataforma Sucupira",
    "section": "",
    "text": "Os dados baixados da Plataforma Sucupira estão na forma de planilhas do Excel, e podem contar informações redundantes e desnecessárias para as análises que queremos fazer, além de necessitarem de organização para facilitar o processamento. Neste documento veremos como transformar as planilhas em bases de dados que facilitarão as análises.",
    "crumbs": [
      "Dados do Coleta",
      "Pré-processamento"
    ]
  },
  {
    "objectID": "sucupira-preprocessamento.html#sobre",
    "href": "sucupira-preprocessamento.html#sobre",
    "title": "Pré-Processamento dos Dados da Plataforma Sucupira",
    "section": "",
    "text": "Os dados baixados da Plataforma Sucupira estão na forma de planilhas do Excel, e podem contar informações redundantes e desnecessárias para as análises que queremos fazer, além de necessitarem de organização para facilitar o processamento. Neste documento veremos como transformar as planilhas em bases de dados que facilitarão as análises.",
    "crumbs": [
      "Dados do Coleta",
      "Pré-processamento"
    ]
  },
  {
    "objectID": "sucupira-preprocessamento.html#reorganizando-as-produções-intelectuais",
    "href": "sucupira-preprocessamento.html#reorganizando-as-produções-intelectuais",
    "title": "Pré-Processamento dos Dados da Plataforma Sucupira",
    "section": "Reorganizando as Produções Intelectuais",
    "text": "Reorganizando as Produções Intelectuais\nAs planilhas dos anos anteriores contém todos os dados submetidos à Plataforma Sucupira, com uma planilha por ano, e com cada planilha representando categorias de dados submetidos à plataforma. Para os exemplos neste documento precisamos somente dos dados de produção científica, que estão armazenados em uma das abas da planilha. Uma cópia da tela da planilha (mostrando algumas de suas abas) e alguns registros sobre a de produção intelectual é mostrada abaixo.\n\nPodemos ver que a produção intelectual não é representada na planilha por um conjunto de linhas e colunas uniforme – os dados de uma produção intelectual estão distribuídos em várias linhas, algumas com pares de campos (detalhamentos da produção) em uma coluna para o nome e uma para o valor do detalhamento; e os nomes e categorias dos autores em colunas separadas. A imagem abaixo mostra o detalhamento de uma única produção contida nesta planilha.\n\nPara algumas das análises que queremos fazer precisamos ler as planilhas, filtrar todas as colunas desnecessárias e recuperar das múltiplas linhas por produção os dados que precisamos, no caso, número de autores por categoria por arquivo. Usaremos Python para este preprocessamento.\nPrimeiro importamos as bibliotecas necessárias:\n\nimport pandas as pd\nimport glob\nimport re\nimport warnings\nfrom IPython.display import Markdown\n\nPara cada planilha vamos ler a aba Produção Intelectual da planilha, filtrar alguns campos que não são necessários e separar somente as linhas que tem nomes de autores. Como repetiremos estes passos para cada planilha é melhor definir uma função em Python que recebe o nome do arquivo e retorna um dataframe com os campos e linhas que precisamos:\n\ndef preprocessaProducoes(fileName):\n    # Lemos a planilha.\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, \n                                module=re.escape('openpyxl.styles.stylesheet'))\n        df = pd.read_excel(fileName,engine='openpyxl',sheet_name='Produção Intelectual')\n    # Removemos os campos indesejados.    \n    drop = ['Calendário', 'Ano do Calendário', \n            'Data-Hora do Envio','Código do PPG','Nome do PPG',\n            'Área de Avaliação','IES Sigla','IES Nome',\n            'Nome do Detalhamento','Valor do Detalhamento','Número de Ordem Autor'\n             ]\n    df = df.drop(columns=drop)\n    # Removemos os campos onde 'Nome do Autor' estiver vazio.\n    df = df.dropna(subset=['Nome do Autor'])\n    return df\n\nA biblioteca usada para a leitura de planilhas gera advertências no código, para isto usamos filtros de alertas (veja mais detalhes aqui).\nOs dados que precisamos estão todos armazenados em planilhas, uma por ano, em um diretório (a lista de planilhas para este documento pode ser vista aqui):\n\ndir = \"Resources/Data/ColetaSucupira/\"\n\nPodemos então criar uma lista de arquivos com nomes semelhantes no diretório indicado e uma lista de dataframes para receber os dados:\n\nfileNames = glob.glob(dir+\"relatorio_dados_enviados_coleta_20??.xlsx\")\ndfs = []\n\nAgora podemos ler cada um destes arquivos, filtrar linhas e colunas e anexar o dataframe filtrado à lista de dataframes:\n\nfor file in fileNames:\n    df = preprocessaProducoes(file)\n    dfs.append(df)\n\nEm uma linha concatenaremos todos os dataframes da produção intelectual do conjunto de planilhas:\n\ndfconcatenado = pd.concat(dfs, ignore_index=True)    \n\nDevemos manter somente as produções que não foram glosadas:\n\ndfconcatenado = dfconcatenado[dfconcatenado['Produção Glosada?'] == 'Não']\ndfconcatenado.drop(columns=['Produção Glosada?'], inplace=True)\n\nAgora temos todas as produções intelectuais de todos os anos que foram coletados na Plataforma Sucupira sobre nosso programa de pós-graduação. Mas estes dados ainda não estão prontos para a análise que queremos fazer: cada registro no dataframe contém informação sobre uma produção e um autor, portanto uma produção com quatro autores está representada em quatro registros.\nPodemos entender melhor este dataframe temporário criando um subconjunto dele contendo somente registros do artigo “A PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS”. Para visualizar melhor este subconjunto visualizando-o como uma tabela (eliminando antes alguns campos redundantes para facilitar a visualização):\n\ndfamostra = dfconcatenado.loc[dfconcatenado['Título da Produção'] == \n           'A PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS']\ndfamostra = dfamostra.drop(columns=['Área de Concentração','Linha de Pesquisa','Projeto de Pesquisa'])\n\nA amostra do dataframe pode ser visualizado com o código abaixo:\n\nMarkdown(dfamostra.to_markdown(index=False))\n\n\n\n\n\n\n\n\n\n\n\n\nAno da Produção\nTítulo da Produção\nTipo da Produção\nSubtipo da Produção\nNome do Autor\nCategoria do Autor\n\n\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nFABIANA ZIOTI\nEgresso - null\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nKARINE REIS FERREIRA GOMES\nDocente\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nGILBERTO RIBEIRO DE QUEIROZ\nDocente\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nALANA KASAHARA NEVES\nParticipante Externo\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nFELIPE MENINO CARLOS\nDiscente - Mestrado\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nFELIPE CARVALHO DE SOUZA\nEgresso - null\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nLORENA ALVES DOS SANTOS\nEgresso - null\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\nROLF EZEQUIEL DE OLIVEIRA SIMOES\nEgresso - null\n\n\n\n\n\nA tabela acima mostra que os valores dos campos Título da Produção, Tipo da Produção e Subtipo da Produção são os mesmos para a produção. Cada autor da produção aparece em um registro do dataframe com sua categoria. O que precisamos, para esta análise, é saber para cada produção quantos autores de cada categoria temos. Para isto precisamos do código a seguir:\n\ndfProdAnter = dfamostra.pivot_table(index=['Ano da Produção', 'Título da Produção', \n                                           'Tipo da Produção', 'Subtipo da Produção'],\n                                           columns='Categoria do Autor',\n                                           values='Nome do Autor',\n                                           aggfunc='count',\n                                           fill_value=0).reset_index()\n\nO código acima cria um novo dataframe a partir da amostra usando como identificador único das produção uma combinação dos campos Ano da Produção, Título da Produção, Tipo da Produção e Subtipo da Produção; criando novos campos com os valores presentes na coluna Categoria do Autor e contando os nomes em cada categoria para cada identificador único. Campos com contagem inexistente serão preenchidos com zeros.\nPodemos visualizar o resultado na tabela abaixo.\n\nMarkdown(dfProdAnter.to_markdown(index=False))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAno da Produção\nTítulo da Produção\nTipo da Produção\nSubtipo da Produção\nDiscente - Mestrado\nDocente\nEgresso - null\nParticipante Externo\n\n\n\n\n2022\nA PLATFORM FOR LAND USE AND LAND COVER DATA INTEGRATION AND TRAJECTORY ANALYSIS\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\n1\n2\n4\n1\n\n\n\n\n\nCom o resultado comprovado podemos criar um dataframe que indica quantos autores por categoria para cada produção temos na base inteira.\n\ndfProdAnter = dfconcatenado.pivot_table(index=['Ano da Produção', 'Título da Produção', \n                                               'Tipo da Produção', 'Subtipo da Produção'],\n                                               columns='Categoria do Autor',\n                                               values='Nome do Autor',\n                                               aggfunc='count',\n                                               fill_value=0).reset_index()\n\nVamos renomear o campo Egresso - null, criado pelos procedimentos anteriores a partir dos valores do campo Categoria do Autor.\n\ndfProdAnter.rename(columns={'Egresso - null': 'Egresso'}, inplace=True)\n\nVamos também armazenar este dataframe em um arquivo para uso posterior.\n\ndfProdAnter.to_csv(dir+\"CategoriaDeAutoresPorProdução-AnosAnteriores.csv\",index=False)                                     \n\nVejamos os primeiros cinco registros deste novo dataframe:\n\nMarkdown(dfProdAnter.head(5).to_markdown(index=False))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAno da Produção\nTítulo da Produção\nTipo da Produção\nSubtipo da Produção\nDiscente - Doutorado\nDiscente - Mestrado\nDocente\nEgresso\nParticipante Externo\nPós-Doc\nSem Categoria\n\n\n\n\n2014\n‘MODELAGEM DE TURBULÊNCIA EM CAMADA LIMITE ATMOSFÉRICA / ATMOSPHERIC BOUNDARY LAYER TURBULENCE MODELLING’\nTÉCNICA\nAPRESENTAÇÃO DE TRABALHO\n0\n0\n1\n0\n0\n0\n0\n\n\n2014\n‘TURBULÊNCIA EM EVOLUÇÃO COSMOLÓGICA / TURBULENCE IN COSMOLOGICAL EVOLUTION’\nTÉCNICA\nAPRESENTAÇÃO DE TRABALHO\n0\n0\n1\n0\n0\n0\n0\n\n\n2014\n8TH BRAZILIAN WORKSHOP ON SYSTEMATIC AND AUTOMATED SOFTWARE TESTING (SAST 2014)\nTÉCNICA\nORGANIZAÇÃO DE EVENTO\n0\n0\n1\n0\n1\n0\n0\n\n\n2014\nA CLUSTERING SEARCH METAHEURISTIC FOR THE POINT-FEATURE CARTOGRAPHIC LABEL PLACEMENT PROBLEM\nBIBLIOGRÁFICA\nARTIGO EM PERIÓDICO\n0\n0\n1\n0\n3\n0\n0\n\n\n2014\nA CONSENSUS-BASED SEMI-SUPERVISED GROWING NEURAL GAS\nBIBLIOGRÁFICA\nTRABALHO EM ANAIS\n0\n0\n1\n0\n2\n0\n0\n\n\n\n\n\n\nComplementando com dados de produções do ano corrente\nA planilha com dados do ano corrente (o que está em preenchimento na Plataforma Sucupira ou que foi enviada no ano) tem um formato ligeiramente diferente do das planilhas dos anos já preenchidos. A figura a seguir mostra uma cópia da tela da planilha do ano corrente (no caso, 2023), mostrando os registros da produção intelectual.\n\nNesta planilha uma produção intelectual também é representada por um conjunto de linhas e colunas, com nomes e categorias de coautores em linhas separadas. A imagem abaixo mostra o detalhamento de uma única produção contida nesta planilha.\n\nNesta seção iremos formatar estes dados de forma a deixá-los compatíveis com os que foram coletados nos anos passados.\nDepois de baixar a planilha com dados do ano corrente e renomeá-la adequadamente podemos usar o código abaixo para ler a única aba (Produções - Autores) em um dataframe.\n\nfilename = \"ListaReplicadaComAutores.xls\"\nwith warnings.catch_warnings():\n     warnings.filterwarnings(\"ignore\", category=UserWarning, \n                             module=re.escape('openpyxl.styles.stylesheet'))\n     df = pd.read_excel(dir+filename,engine='openpyxl',sheet_name='Produções - Autores')\n\nPara eliminar as colunas do dataframe que não serão necessárias usamos o código a seguir:\n\nkeep = ['Ano da Produção','Nome da Produção','Tipo de Produção',\n        'Subtipo de Produção','Nome do Autor','Categoria do Autor']\ndf = df.drop(columns=[col for col in df.columns if col not in keep])\n\nOutro passo no processamento dos dados da planilha das produções do ano corrente é renomear algumas colunas para que fiquem compatíveis com as planilhas das produções dos anos anteriores.\n\ndf.rename(columns={'Nome da Produção': 'Título da Produção', \n                   'Tipo de Produção': 'Tipo da Produção', \n                   'Subtipo de Produção': 'Subtipo da Produção'}, inplace=True)\n\nPodemos reorganizar o dataframe para conter somente uma publicação por linha e com a contagem de autores por categorias com o código abaixo:\n\ndfProdAtual = df.pivot_table(index=['Ano da Produção', 'Título da Produção', \n                                    'Tipo da Produção', 'Subtipo da Produção'],\n                                    columns='Categoria do Autor',\n                                    values='Nome do Autor',\n                                    aggfunc='count',\n                                    fill_value=0).reset_index()\n\nFinalmente armazenamos este dataframe para uso posterior.\n\ndfProdAtual.to_csv(dir+\"CategoriaDeAutoresPorProdução-AnoCorrente.csv\",index=False)                                     \n\n\n\nUnificando as bases de dados de Produções Intelectuais\nNeste ponto temos duas bases de dados: CategoriaDeAutoresPorProdução-AnosAnteriores.csv e CategoriaDeAutoresPorProdução-AnoCorrente.csv. Embora as duas representem basicamente as mesmas informações, o formato é ligeiramente diferente na ordem das colunas e nos campos, que podem ser diferentes dependendo das categorias de coautores presentes nas planilhas originais. O código nesta seção ajusta e unifica os dados.\nA planilha com os dados de anos anteriores diferencia entre coautores de categorias Discente - Mestrado e Discente - Doutorado, mas a do ano atual não. Devemos então unificar as colunas Discente - Mestrado e Discente - Doutorado do dataframe contendo a produção intelectual dos anos anteriores, armazenando a soma na coluna nova Discente.\n\ndfProdAnter = dfProdAnter.assign(Discente=lambda x: x['Discente - Doutorado'] + x['Discente - Mestrado'])\ndfProdAnter = dfProdAnter.drop(columns=['Discente - Doutorado', 'Discente - Mestrado'])\n\nCom isto posso unificar os dataframes contendo a produção intelectual dos anos anteriores e a do ano atual. O dataframe resultante receberá todas as linhas e colunas dos dataframes unificados, e onde um campo não tiver correspondência preencheremos o seu valor com zero:\n\ncomuns = list(set(dfProdAnter.columns) & set(dfProdAtual.columns))\ndfProdUnificada = pd.merge(dfProdAnter, dfProdAtual, on=comuns, how='outer')\ndfProdUnificada.fillna(0, inplace=True)\n\nSalvamos também este dataframe para uso posterior.\n\ndfProdUnificada.to_csv(dir+\"CategoriaDeAutoresPorProdução-Unificada.csv\",index=False)",
    "crumbs": [
      "Dados do Coleta",
      "Pré-processamento"
    ]
  }
]